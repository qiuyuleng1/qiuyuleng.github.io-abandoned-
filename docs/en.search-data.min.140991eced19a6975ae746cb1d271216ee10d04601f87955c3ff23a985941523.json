[{"id":0,"href":"/docs/stage1/ansible/","title":"Ansible","section":"Docs","content":"Inventory file alias(别名)\nansible_host=IP/FQDN(fully qualified domain name, 完整域名)\nansible_connection=ssh/winrm/localhost\nansible_port=22(default for ssh)\nansible_user=root/administrator\nansible_ssh_pass(ansible_password for win)=password\n[group_name1]\nGroupmember_alias1 or host\n[group_name2]\nGroupmember_alias2 or host\n[group_name3:children] 继承\ngroup_name1\ngroup_name2\nYMAL Key :(colon) value\n冒号后面一定要加空格！\n"},{"id":1,"href":"/docs/stage2/docker-in-action/","title":"Docker in Action","section":"Docs","content":"Introduction Chapter 1: Welcome to Docker Docker make it easier for users to install and run the software. Docker is a tool helping solve common problems such as installing, removing, upgrading, distributing, trusting and running software, helping system administrators focus on higher-value activities. What is Docker? Docker is an open source project for building, shipping and running programs. containers Install Docker https://docs.docker.com/engine/install/ubuntu/#install-using-the-repository Take care of the setting of proxy https://docs.docker.com/config/daemon/systemd/#httphttps-proxy https://docs.docker.com/network/proxy/ Hello World 本机上没有这个image 本机上有这个image Containers and Docker Containers can isolate a process from all resources except where explicitly allowed. However, it is challenging to to manually built correctly. Docker solved this problem. Docker makes container simpler to use. Containers are not virtualization Virtual machines require high resource overhead (because they run a whole OS) and requires a long time to startup. Docker (containers) solved this problem. Container is an OS feature. Running software in containers for isolation\nPrograms run inside a container can access only their own memory and resources as scoped by the container. Docker build container using 10 major system features to suit the needs of the contained software and fit the environment the container will run. Shipping containers image: component in the container (shipping units) Docker image is a bundled snapshot of all files needed for program running inside a container. Containers that were started from the same image don’t share changes to their filesystem. registries and indexes What problems does Docker solve? Get organized\nImprove portability 便携性 On macOS and Windows, Docker uses a single, small virtual machine to run all the containers. Developer could focus on writing programs on a single platform. Protect your computer also protect from the software inside a container\nWhy is Docker Important? \u0026amp; When and where to use Docker? Docker provides an abstraction.\nKeep your computer clean.\nSecurity issues.\nGetting help with the Docker command line docker help\ndocker help e.g. docker help ps\nPart 1: Process isolation and environment-independent computing Chapter 2: Running software in containers Controlling containers: Building a website monitor\nNGINX and mailer run as detached containers. Detached means the container will run in the background, without being attached to any input or output stream. Watcher runs as interactive container. Steps:\nCreating and starting a new container: detached containers docker run \u0026ndash;detach \u0026ndash;name web nginx:latest \u0026ndash;detach or -d means the program is started in the background and is not attached to your terminal (cannot be found in ps -l ), called daemon Running interactive containers docker run \u0026ndash;interactive \u0026ndash;tty \u0026ndash;link web:web \u0026ndash;name web_test busybox:1.29 /bin/sh \u0026ndash;interactive : keep the standard input open for the container even if no terminal is attached \u0026ndash;tty : allocate a virtual terminal for the container Usually use both of these when running an interactive program docker run -it \u0026ndash;name agent \u0026ndash;link web:insideweb \u0026ndash;link mailer:insidemailer dockerinaction/ch2_agent Hold ctrl and press P and then Q to return to the shell. Listing, stopping, restarting, and viewing output of containers docker ps shows information for each running containers docker logs container_name check the logs for container docker stop container_name stop a container Solved problems and the PID namespace Docker creates a new PID namespace for each container by default\ndocker exec container_name command run a command in a running container docker exec container_name ps to show all the running processes and their PID in the container docker run \u0026ndash;pid host busybox:1.29 ps to create containers without their own PID namespace. could see all process in the host server. Conflict problems could be solved by docker due to environment independence\nOther conflict problems that docker could solve:\nBy using Linux namespaces, resource limits, filesystem roots, virtualized network components. Eliminating metaconflicts: Building a website farm Flexible container identification: deal with container name collisions docker rename new-name old-name rename a container container ID, could use the first 12 chars. docker create creates a container in a stopped state. docker create \u0026ndash;cidfile /tmp/web.cid nginx write container ID (CID) to a known file. Docker won\u0026rsquo;t create a new container if the provided CID file already exits. To avoid conflict, we can use a partition path, such as /containers/web/customer1/web.cid docker ps \u0026ndash;latest \u0026ndash;quiet get the CID of the last container. docker could generates human-readable names for each container ( \u0026ndash;name flag override it) Container state and dependencies\ndocker ps -a to see all the containers The order of starting containers generate an IP addr when creating containers Building environment-agnostic systems To help build environment-agnostic system, Docker has three specific features:\nRead-only filesystems Environment variable injection Volumes Read-only filesystems docker inspect \u0026ndash;format \u0026ldquo;{{.State.Running}}\u0026rdquo; wp inspect the container metadata directly. \u0026ndash;format with Go template docker diff CONTAINER Inspect changes to files or directories on a container\u0026rsquo;s filesystem docker run -d \u0026ndash;name wp2 \u0026ndash;read-only -v /run/apache2/ \u0026ndash;tmpfs /tmp wordpress:5.0.0-php7.2-apache #!/bin/sh DB_CID=$(docker create -e MYSQL_ROOT_PASSWORD=ch2demo mysql:5.7) docker start $DB_CID MAILER_CID=$(docker create dockerinaction/ch2_mailer) docker start $MAILER_CID WP_CID=$(docker create \u0026ndash;link $DB_CID:mysql -p 80 \u0026ndash;read-only -v /run/apache2/ \u0026ndash;tmpfs /tmp wordpress:5.0.0-php7.2-apache) docker start $WP_CID AGENT_CID=$(docker create \u0026ndash;link $WP_CID:insideweb \u0026ndash;link $MAILER_CID:insidemailer dockerinaction/ch2_agent) docker start $AGENT_CID Environment variable injection Environment variable: change programs\u0026rsquo; configuration without modifying any files docker run \u0026ndash;env (-e) ENVIRONMENT_VAR=my_environment_vat busybox:1.29 env Injects an environment variable\nBuilding durable containers Restore the container service as quickly as possible.\nBasic strategy: automatically restarting a process when it exits or fails.\nAutomatically restarting containers \u0026ndash;restart flag\nBackoff strategy: determines the amount of time that should pass between successive restart attempts. Exponential backoff strategy Issues: containers waiting to be restarted are in the restarting state, and we cannot do anything that requires the container to be in a running state (such as docker exec ) Using PID 1 and init systems Init system: a program that\u0026rsquo;s used to launch and maintain the state of other programs. e.g.: runit, Yelp/dumb-init, tini, supervisord, and tianon/gosu. docker run -d -p 80:80 \u0026ndash;name lamp-test tutum/lamp docker top CONTAINER Display the running processes of a container An alternative method of init system: using a startup script docker run \u0026ndash;entrypoint=\u0026ldquo;cat\u0026rdquo; wordpress:5.0.0-php7.2-apache /usr/local/bin/docker-entrypoint.sh \u0026ndash;entrypoint Docker containers run something called an entrypoint before executing the command Cleaning up docker rm CONTAINER For container in running process, using docker stop first (better), or using docker rm -f CONTAINER (for quick stop). docker run \u0026ndash;rm Automatically remove the container as soon as it enters the exited state. docker rm -vf $(docker ps -a -q) Clean (kill) all the containers. Chapter 3: Software installation simplified\nIdentifying software What is a named repository? It is a named bucket of images, similar to a URL.\nA repository can hold several images, identified uniquely with tags.\nName and tag form a composite key, e.g., nginx:latest\nUsing tags A tag can only attach to one image, while one image can have several tags.\ncreate useful aliases different tags for different versioning different tags for different software configurations Finding and installing software\nFind software using index. Docker Hub is one of the public Docker indexes, and is the default registry and index used by docker.\nWorking with Docker registries from the command line docker login before publishing images.\nUsing alternative registries Registry address is part of the full repository specification.\n[REGISTRYHOST:PORT/][USERNAME/]NAME[:TAG]\nJust specify the registry host, e.g., docker pull quay.io/dockerinaction/ch3_hello_registry:latest\nWorking with images as files Using docker load command.\nBefore this, we need to save one image from a loaded image docker save -o filename.tar busybox:latest\nRemove image from docker docker rmi busybox\nLoad it again docker load -i myfile.tar\nCheck it docker images to list images.\nInstalling from a Dockerfile git clone https://github.com/dockerinaction/ch3_dockerfile.git\ndocker build -t dia_ch3/dockerfile:latest ch3_dockerfile\nUsing Docker Hub from the website https://hub.docker.com\nInstallation files and isolation layer: a set of files and file metadata that is packaged and distributed as an atomic unit, called intermediate images.\nImage layers in action Layer relationships Docker can uniquely identifies images and layers, it is able to recognize shared image dependencies between applications and avoid download those dependencies again.\nContainer filesystem abstraction and isolation: Union filesystem Union filesystem (UFS) is used to create mount point and abstract the use of layers.\nWhen Docker creates a container, that new container will have its own MNT namespace, and a new mount point will be created for the container to the image. chroot is used to prevent from referring any other part of the host filesystem in the container. Benefits of this toolset and filesystem structure Common layers need to be installed only once. Layers could manage dependencies and separating concerns. Create software specializations when you can layer minor changes on top of a basic image. Weaknesses of union filesystems Often need to translate between the rules of different filesystems. Chapter 4: Working with storage and volumes Manage data with containers: where is the data stored? what happens to that data when you stop the container or remove it?\nFile trees and mount points the image that a container is created from is mounted at that container’s file tree root, or the / point every container has a different set of mount points Containers get access to storage on the host filesystem and share storage between containers: mount nonimage-related storage at other points in a container file tree. Three types of storage mounted into containers: bind mount in-memory storage docker volumes\n\u0026ndash;mount flag in docker run and docker create Bind mounts Bind mounts attach a user-specified location on the host filesystem to a specific point in a container file tree.\nhost provides files or dictionaries need by the program running in a container. containerized program produces a file or log need to be processed outside containers. An example\ntouch ~/example.log cat \u0026gt;~/example.conf \u0026laquo;EOF server { listen 80; server_name localhost; access_log /var/log/nginx/custom.host.access.log main; location / { root /usr/share/nginx/html; index index.html index.htm; } } EOF CONF_SRC=~/example.conf; CONF_DST=/etc/nginx/conf.d/default.conf; LOG_SRC=~/example.log; LOG_DST=/var/log/nginx/custom.host.access.log; docker run -d \u0026ndash;name diaweb \\\n\u0026ndash;mount type=bind,src=${CONF_SRC},dst=${CONF_DST},readonly=true \u0026ndash;mount type=bind,src=${LOG_SRC},dst=${LOG_DST} -p 80:80 nginx:latest src : source location on the host file tree (name of the volume, for anonymous volumes, this field is omitted) dst : destination location on the container file tree readonly=true prevent modifying the content of the volume Test: docker exec diaweb sed -i \u0026ldquo;s/listen 80/listen 8080/\u0026rdquo; /etc/nginx/conf.d/default.conf Problems:\nportable conflict with other containers In-memory storage Private files should use in-memory storage, instead of including in an image or writing them to disk.\ndocker run \u0026ndash;rm \u0026ndash;mount type=tmpfs,dst=/tmp,tmpfs-size=16k,tmpfs-mode=1770 \u0026ndash;entrypoint mount alpine:latest -v Set the type option on the mount flag to tmpfs. File permissions 1770 (1777 for default) Size limit 16k Docker volumes Introduction to volumes It is used to organizing data: in disk space that can be accessed by containers.\ndo not need to concern the system (fill on any machine with Docker installed). easy to clean up for Docker (life cycle) It could decouple storage from specialized locations on the filesystem that you might specify with bind mounts, and could run o any machine without considering conflict.\nUsing docker volume subcommand set.\ndocker volume create \u0026ndash;driver local \u0026ndash;label example=location location-example\ndocker volume inspect \u0026ndash;format \u0026ldquo;{{json .Mountpoint}}\u0026rdquo; location-example\n–-driver local: create a directory to store the contents of volume in a part of the host filesystem under control of the Docker engine.\nHow to share volumes between containers without exposing the exact location of managed containers?\nVolumes provide container-independent data management images are appropriate for packaging and distributing relatively static files such as programs (reusable) volumes hold dynamic data or specializations (simple to share). Polymorphic 多态：using volumes, do not need to modify an image.\nUsing volumes with a NoSQL database Create a single-node Cassandra cluster, create a keyspace, delete the container, and then recover that keyspace on a new node in another container:\ndocker volume create \u0026ndash;driver local \u0026ndash;label example=cassandra cass-shared\ndocker run -d \u0026ndash;volume cass-shared:/var/lib/cassandra/data \u0026ndash;name cass1 cassandra:2.2 Shared mount points and sharing files Sharing access to the same set of files between multiple containers.\nBind mounts methods: may lead to conflict. Use volumes: do not need the knowledge of the underlying host filesystem. Anonymous volumes and the volumes-from flag Volume is created without a human-friendly name, and is assigned a unique identifier to eliminate volume-naming conflicts.\n\u0026ndash;volumes-from : copy the definition from other containers to the new container. (copy the full volume definition, including mount point, permission)\nSituations not suit for \u0026ndash;volumes-from : when you need tomount to a different location conflict: volumes from different containers with the same mount point\ndocker run \u0026ndash;name chomsky \u0026ndash;volume /library/ss alpine:latest echo \u0026ldquo;Chomsky collection created.\u0026rdquo; docker run \u0026ndash;name lamport \u0026ndash;volume /library/ss alpine:latest echo \u0026ldquo;Lamport collection created.\u0026rdquo;\ndocker run \u0026ndash;name student \u0026ndash;volumes-from chomsky \u0026ndash;volumes-from lamport alpine:latest ls -l /library/\ndocker inspect -f \u0026ldquo;{{json .Mounts}}\u0026rdquo; student\nOnly one of the two containers is mounted. # when you need to change the write permission of a volume Cleaning up volumes docker volume list to list all the volumes\ndocker volume remove VOLUME_NAME/Unique_identifier to remove the volume\nsupport list argument, such as docker volume remove amazon google microsoft volume in use cannot be remove docker volume prune delete all volumes that can be deleted\n\u0026ndash;filter : filter –-force : without confirmation step Advanced storage with volume plugins For a cluster of machines, need to choose storage infrastructure, such as network storage\nneed to select proper Docker plugin.\nChapter 5: Single-host networking How to connect a container to the network.\nNetworking background Basics: Protocols, interfaces, and ports Protocol: communication and networking in a sort of language, such as HTTP Interface: address, represents a location IP address: unique, information about their location on their network Ethernet interface and loopback interface Port: a recipient or a sender Bigger picture: Networks, NAT and port forwarding bridge: an interface that connects multiple networks so that they can function as a single network. selectively forwarding traffic between the connected networks based on another type of network address. Docker container networking Benefits: 1. keep environment agnosticism 2. adopt specific network implementation\nProblems: hard to determine the IP address of host, and inhibits container to other services outside the container network.\ndocker network subcommands\ndocker network ls to list all network of Docker.\nbridge: inter-container connectivity for all containers running on the same machine host: not create any networking namespace for attached container. Container will interact with host\u0026rsquo;s network like uncontained processes. none: no network connectivity scope: local, global and swarm local: the network is constrained to the machine where the network exists global: created on every node in a cluster but not route between them swarm: span all of the hosts participating in a Docker swarm Creating a user-defined bridge network Local to the machine where Docker is installed, creates route between participating containers and the wider network where the host is attached.\nshape bridge network to fit your environment\ndocker network create \u0026ndash;driver bridge \u0026ndash;label project=dockerinaction \u0026ndash;label chapter=5 \u0026ndash;attachable \u0026ndash;scope local \u0026ndash;subnet 10.0.42.0/24 \u0026ndash;ip-range 10.0.42.128/25 user-network\ndocker network create \u0026ndash;driver bridge \u0026ndash;label project=dockerinaction \u0026ndash;label chapter=5 \u0026ndash;attachable \u0026ndash;scope local \u0026ndash;subnet 10.0.43.0/24 \u0026ndash;ip-range 10.0.43.128/25 user-network2 attach a running container to more than one network\ndocker run -it \u0026ndash;network user-network \u0026ndash;name network-explorer alpine:3.8 sh\nip -f inet -4 -o addr\ndocker network connect user-network2 network-explorer\nip -f inet -4 -o addr nmap -sn 10.0.42.* -sn 10.0.43.* -oG /dev/stdout | grep Status what those networks look like to running software inside an attached container\ndocker run -d \u0026ndash;name lighthouse \u0026ndash;network user-network2 alpine:3.8 sleep 1d\nnmap -sn 10.0.42.* -sn 10.0.43.* -oG /dev/stdout | grep Statu For situations that route traffic between containers on different machines, can use underlay networks provided by the macvlan or ipvlan network drivers.\nor use swarm mode Special container networks: host and none software inside the container have the same degree of access to the host network as software outside container\ndocker run \u0026ndash;rm \u0026ndash;network host alpine:3.8 ip -o addr software in the container cannot reach anything outside the container (network isolate)\ndocker run \u0026ndash;rm \u0026ndash;network none alpine:3.8 ip -o addr\ndocker run \u0026ndash;rm \u0026ndash;network none alpine:3.8 ping -w 2 1.1.1.1 Handling inbound traffic with NodePort publishing Need to tell Docker how to forward traffic from the external network interfaces: specify TCP or UDP port.\nNodePort publishing: match Docker and other ecosystem projects.\nProvided at container creation time and cannot be changed later docker run/create \u0026ndash;publish colon-delimited string argument.\nExamples:\ndocker run \u0026ndash;rm -p 8080 alpine:3.8 echo \u0026ldquo;forward ephemeral TCP -\u0026gt; container TCP 8080\u0026rdquo; Host operating system will select a random host port, and traffic will be routed to port 8080 in the container. Since ports are scarce resources, and this way will avoid potential conflicts. Programs running inside a container do not know which port is being forwarded from the host use docker port listener to look up port mappings lookup special container port and protocol\ndocker run -d -p 8080 -p 3000 -p 7500 \u0026ndash;name multi-listener alpine:3.8 sleep 300\ndocker port multi-listener 3000 Container networking caveats and customizations No firewalls or network policies Docker bridge networks do not provide any network firewall or access-control functionality.\nCustom DNS configuration at /etc/hosts inside your container\ndocker run \u0026ndash;hostname set hostname of a new container, other containers do not know this hostname. docker run \u0026ndash; dns use an external DNS server docker run \u0026ndash;dns-search=[] provide a default hostname suffix. e.g., docker run \u0026ndash;rm \u0026ndash;dns-search docker.com alpine:3.8 nslookup hub will resolve the IP addr of hob.docker.com docker run \u0026ndash;add-host Externalizing network management use Docker none network + third party container-aware tools.\nChapter6: Limiting risk with resource controls Set resource allowances By default, Docker containers may use unlimited CPU, memory, and device I/O resources.\nMemory limits docker run/create \u0026ndash;memory where unit = b, k, m or g Note that they are not reservations, and only a protection from overconsumption. Is the memory enough for the container? docker stats CONTAINER_NAME Some programs may fail with a memory access fault, whereas others may start writing out-of-memory errors to their logging. \u0026ndash;restart CPU specify the relative weight of a container to other containers \u0026ndash;cpu-shares flag. Only enforced only when there is contention for time on the CPU limit the total amount of CPU used by a container \u0026ndash;cpus the number of CPU cores the container should be able to use enforced assign a container to a specific CPU set. avoid context switch Access to devices More like resource-authorization control than a limit.\n\u0026ndash;device : + a map between the device file on the host operating system and the location inside the new container\nSharing memory Docker creates a unique IPC namespace for each container by default, which prevents processes in one container from accessing the memory on the host or in other containers\nSharing IPC primitives between containers \u0026ndash;ipc flag\nrun programs that communicate with shared memory in different containers create a new container in the same IPC namespace as another target container\nsharing memory with host \u0026ndash;ipc=host Understanding users User is specified by the image metadata by default, often the root user.\nWorking with the run-as user docker inspect \u0026ndash;format \u0026ldquo;{{.Config.User}}\u0026rdquo; busybox:1.29 : if blank, the container will default to running as the root user.\nuser might be changed docker container run \u0026ndash;rm \u0026ndash;entrypoint \u0026quot;\u0026quot; busybox:1.29 whoami\ndocker container run \u0026ndash;rm \u0026ndash;entrypoint \u0026quot;\u0026quot; busybox:1.29 id\nTo run as specific user when creating the container, the username must exist on the image you are using.\nget a list of available user in an image with docker container run \u0026ndash;rm busybox:1.29 awk -F: \u0026lsquo;$0=$1\u0026rsquo; /etc/passwd docker container run \u0026ndash;rm \u0026ndash;user nobody busybox:1.29 id Users and volumes User ID space is shared: both root on the host and root in the container have user ID 0.\ncontainer\u0026rsquo;s root can access a file owned by root on the host do not mount the file into that container with a volume echo \u0026ldquo;e=mc^2\u0026rdquo; \u0026gt; garbage chmod 600 garbage sudo chown root garbage docker container run \u0026ndash;rm -v \u0026ldquo;$(pwd)\u0026quot;/garbage:/test/garbage -u nobody ubuntu:16.04 cat /test/garbage docker container run \u0026ndash;rm -v \u0026ldquo;$(pwd)\u0026quot;/garbage:/test/garbage -u root ubuntu:16.04 cat /test/garbage\nOutputs: \u0026ldquo;e=mc^2\u0026rdquo; # Specify the desired user and group ID to avoid file permission conflicts.\nmkdir logFiles sudo chown 2000:2000 logFiles docker container run \u0026ndash;rm -v \u0026ldquo;$(pwd)\u0026quot;/logFiles:/logFiles -u 2000:2000 ubuntu:16.04 /bin/bash -c \u0026ldquo;echo This is important info \u0026gt; /logFiles/important.log\u0026rdquo; docker container run \u0026ndash;rm -v \u0026ldquo;$(pwd)\u0026quot;/logFiles:/logFiles -u 2000:2000 ubuntu:16.04 /bin/bash -c \u0026ldquo;echo More info \u0026raquo; /logFiles/important.log\u0026rdquo; Be careful about which user can control the Docker daemon.\nIntroduction to the Linux user namespace and UID remapping By default, Docker containers do not use the USR namespace\nA container running with a user ID that is the same as a user on the host machine has the same host file permissions as that user. When user namespace is enable: UID namespace remapping\nremap to unprivileged UID dockremap user Adjusting OS feature access with capabilities Capabilities: OS feature authorization\nList all default caoabilities:\ndocker container run \u0026ndash;rm -u nobody ubuntu:16.04 /bin/bash -c \u0026ldquo;capsh \u0026ndash;print | grep net_raw\u0026rdquo;\n\u0026ndash;cap-drop : drop capabilities during container run/create\n\u0026ndash;cap-add : add capabilities\nRunning a container with full privileges Run a system administration task: privileged containers\nPrivileged containers maintain their filesystem and network isolation but have full access to shared memory and devices and possess full system capabilities.\n\u0026ndash;privileged for docker container create/run\nStrengthening containers with enhanced tools Specifying additional security options \u0026ndash;security-opt\nSELinux: labeling\nAppArmor: file path\nBuilding use-case-appropriate containers Start with the most isolated container you can build and justify reasons for weakening those restrictions.\nOr use default container construction.\nApplications running as a user with limited permissions limit the system capabilities set limits on how much of the CPU and memory the application can use specifically whitelist devices that it can access High-level system services Often require privileged access, including cron, syslogd, sshd and so on.\nUse capabilities to tune their access.\nLow-level system services Require privileged access, including devices and system\u0026rsquo;s network stack. Rare to run inside containers.\nUsed for short-running configuration containers: change the configuration with a privileged containers.\nPart 2: Packaging software for distribution Chapter 7: Packaging software in images Building Docker images from a container\nTips: docker run is the same as docker container run. https://stackoverflow.com/questions/51247609/difference-between-docker-run-and-docker-container-run\ndocker container diff CONTAINER_NAME review the list of files that have been modified in a container (added A, changed C, deleted D) docker container commit commit changes to new image -a flag: author -m flag: commit message add \u0026ndash;entrypoint Parameters that carry forward with an image created from the container.\nall environment variables working directory the set of exposed ports all volume definitions the container entrypoint command and arguments Note: If not specifically set for the container, the values will be inherited from the original image Going deep on Docker images and layers Exploring union filesystems Each time a change is made to a union filesystem, that change is recorded on a new layer on top of all of the others\nWhen reading a file, the file will be read from the topmost layer where it exist.\nIf a file was not created or changed on the top layer, the read will fall through the layers until it reaches a layer where that file does exist When a file is deleted, a delete record is written to the top layer, which hides any versions of that file on lower layers.\nWhen a file is changed, that change is written to the top layer, which again hides any versions of that file on lower layers\nReintroducing images, layers, repositories, and tags Metadata of layer: generated identifier, identifier of the layer below it, execution context.\nImage: stack of layers, constructed by starting with a given top layer and then following all the links\ndocker commit [OPTIONS] CONTAINER [REPOSITORY[:TAG]] commit container with name and tag.\ndocker tag copy image by creating a new tag or repo from existing one.\nAll layers below the writable layer created for a container are immutable.\nthey can never be modified make individual layers reusable share access to images instead of creating independent copies for every container any time making changes to an image, you need to add a new layer, and old layers are never removed. Managing image size and layer limits Union filesystem makes a file as deleted by actually adding a file to the top layer.\ndocker image history IMAGE show the history of an image.\nExporting and importing flat filesystems image \u0026amp; TAR file: bad idea, will lose the original image\u0026rsquo;s metadata and change history.\ndocker image save save the image to a TAR file. docker image import import the TAR file into docker. docker import -c \u0026ldquo;ENTRYPOINT [\u0026quot;/hello\u0026quot;]\u0026rdquo; - dockerinaction/ch7_static \u0026lt; static_hello.tar -c specify a Dockerfile command\nat the end of the first line: the content of the tarball will be streamed through stdin. This position can be file/URL/- small size, only one layer (called flat image), no layer reuse use creating branch docker container export Export a container\u0026rsquo;s filesystem as a tar archive docker cp Copy files/folders between a container and the local filesystem\nVersioning best practices\nlatest: default tag, should point to the latest stable build of its software instead of the true latest.\nEach row represents a distinct image.\nChapter 8: Building images automatically with Dockerfiles Dockerfile: text file containing instructions for building an image.\nPackaging Git with Dockerfile\nAn example Dockerfile for installing Git on Ubuntu # FROM ubuntu:latest LABEL maintainer=\u0026ldquo;dia@allingeek.com\u0026rdquo; RUN apt-get update \u0026amp;\u0026amp; apt-get install -y git ENTRYPOINT [\u0026ldquo;git\u0026rdquo;] docker image build \u0026ndash;tag ubuntu-git:auto .\n#: comments The first instruction of Dockerfile must be FROM . : the location of the Dockerfile is the current directory. \u0026ndash;file specify the name of Dockerfile, it usually be xxxx.df –quite / -q suppress the output of the build process The use of caching: the builder can cache the results of each step. If a problem occurs after several steps, the builder can restart from the same position after the problem has been fixed.\n\u0026ndash;no-cache : disable caching A Dockerfile primer Metadata instructions Benefits of using Dockerfile: simplify copying files from host computer into an image\ndefine which files should never be copied into any images: .dockerignore Each Dockerfile instruction will result in a new layer being created, so merge instructions to minimize the size of images and layer count when possible.\nFROM debian:buster-20190910 LABEL maintainer=\u0026ldquo;dia@allingeek.com\u0026rdquo; RUN groupadd -r -g 2200 example \u0026amp;\u0026amp; useradd -rM -g example -u 2200 example ENV APPROOT=\u0026quot;/app\u0026rdquo; APP=\u0026ldquo;mailer.sh\u0026rdquo; VERSION=\u0026ldquo;0.6\u0026rdquo; LABEL base.name=\u0026ldquo;Mailer Archetype\u0026rdquo; base.version=\u0026quot;${VERSION}\u0026rdquo; WORKDIR $APPROOT ADD . $APPROOT ENTRYPOINT [\u0026quot;/app/mailer.sh\u0026rdquo;] EXPOSE 33333\nDo not set the default user in the base otherwise # implementations will not be able to update the image # USER example:example # Some Dockerfile instructions:\nFROM : set the layer stack to start from which image. ENV : set environment variables for an image, similar to \u0026ndash;env flag on docker container run/create can also be used in other instructions in this Dockerfile LABEL : defile key:value pairs, similar to \u0026ndash;label on docker run/create\nadd additional metadata, will be available to process running inside a container WORKDIR : set default working directory EXPOSE : open TCP port ENTRYPOINT : set the executable to run at container startup has two forms: shell form and exec form if the shell form is used, all other arguments provided by CMD instruction or extra arguments will be ignored. app/mailer.sh does not exist USER set user and group for further build steps set up user and group accounts in base image let the implementations set the default user use docker inspect to inspect the environment variables of the image. ENV, LABEL, WORKDIR, VOLUME, EXPOSE, ADD, COPY Filesystem Instructions Some instructions that modify the filesystem\nFROM dockerinaction/mailer-base:0.6 RUN apt-get update \u0026amp;\u0026amp; apt-get install -y netcat COPY [\u0026rdquo;./log-impl\u0026quot;, \u0026ldquo;${APPROOT}\u0026rdquo;] RUN chmod a+x ${APPROOT}/${APP} \u0026amp;\u0026amp; chown example:example /var/log USER example:example VOLUME [\u0026quot;/var/log\u0026quot;] CMD [\u0026quot;/var/log/mailer.log\u0026quot;] docker image build -t dockerinaction/mailer-logging -f mailer-logging.df .\nCOPY : at least two argus, source files + destination file ownership set to root support shell style and exec style arguments (exec is better) ADD : fetch remote source files if a URL is specified (not good, did not provide mechanism for cleaning up unused files and results in additional layers) extract the files of any resource determined to be an archive file (auto-extraction) VOLUME : similar to \u0026ndash;volume on docker run/create CMD : related to ENTRYPOINT\nrepresents an argument list for entrypoint if no ENTRYPOINT is set, ignore this instruction If ENTRYPOINT is set and using exec form, you use CMD to set default arguments. Tip: what is shell style and exec style?\nshell style: looks like a shell command with whitespace-delimited arguments can use \u0026ldquo;\u0026quot; to continue a single instruction onto the next line e.g.:\nRUN \u0026lsquo;source $HOME/.bashrc;\\ echo $HOME ' exec form: a string array in which the first value is the command to execute, the remaining values are argus. e.g.: RUN [\u0026quot;/bin/bash\u0026rdquo;, \u0026ldquo;-c\u0026rdquo;, \u0026ldquo;echo hello\u0026rdquo;] Injecting downstream build-time behavior ONBUILD : defines other instructions to execute if the resulting image is used as a base for another build.\nrecorded in the resulting image\u0026rsquo;s metadata under ContainerConfig.OnBuild in the downstream Dockerfiles, those ONBUILD instructions are executed after FROM instruction and before the next instruction. Creating maintainable Dockerfiles ARG : define variable that users can provide to Docker when building an image.\n\u0026ndash;build-arg = Multistage Dockerfile: a Dockerfile that has multiple FROM instructions\neach FROM instruction makes a new build stage FROM \u0026hellip; AS to name build stage, this name can be used in subsequent FROM and COPY \u0026ndash;from=\u0026lt;name|index\u0026gt; example:\n#################################################\nDefine a Builder stage and build app inside it # FROM golang:1-alpine as builder\nInstall CA Certificates # RUN apk update \u0026amp;\u0026amp; apk add ca-certificates\nCopy source into Builder # ENV HTTP_CLIENT_SRC=$GOPATH/src/dia/http-client/ COPY . $HTTP_CLIENT_SRC WORKDIR $HTTP_CLIENT_SRC\nBuild HTTP Client # RUN CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build -v -o /go/bin/http-client #################################################\nDefine a stage to build a runtime image. # FROM scratch as runtime ENV PATH=\u0026quot;/bin\u0026quot;\nCopy CA certificates and application binary from builder stage # COPY \u0026ndash;from=builder /etc/ssl/certs/ca-certificates.crt /etc/ssl/certs/ca-certificates.crt COPY \u0026ndash;from=builder /go/bin/http-client /http-client ENTRYPOINT [\u0026quot;/http-client\u0026quot;] Using startup scripts and multiprocess containers Environmental preconditions validation failing fast and precondition validation are best practices in software design.\nImage author can introduce environment and dependency validation prior to execution of the main task, and to better inform user if the container is failed.\ne.g., WordPress use a script as the container entrypoint to validate environment variables and container links. The startup process could validate\nPresumed links (and aliases) Environment variables Secrets Network access Network port availability Root filesystem mount parameters (read-write or read-only) Volumes Current user Can use shell scripts to finish the above validations.\nExample: validate either another container has been linked to the web alias and has exposed port 80, or the WEB_HOST environment variable has been defined:\n#!/bin/bash set -e if [ -n \u0026ldquo;$WEB_PORT_80_TCP\u0026rdquo; ]; then if [ -z \u0026ldquo;$WEB_HOST\u0026rdquo; ]; then WEB_HOST=\u0026lsquo;web\u0026rsquo; else echo \u0026gt;\u0026amp;2 \u0026lsquo;[WARN]: Linked container, \u0026ldquo;web\u0026rdquo; overridden by $WEB_HOST.\u0026rsquo; echo \u0026gt;\u0026amp;2 \u0026ldquo;===\u0026gt; Connecting to WEB_HOST ($WEB_HOST)\u0026rdquo; fi fi if [ -z \u0026ldquo;$WEB_HOST\u0026rdquo; ]; then echo \u0026gt;\u0026amp;2 \u0026lsquo;[ERROR]: specify container to link; \u0026ldquo;web\u0026rdquo; or WEB_HOST env var\u0026rsquo; exit 1 fi exec \u0026ldquo;$@\u0026rdquo; # run the default command The same containers may fail later for other reasons → can combine startup scripts with container restart policies.\nInitialization processes Initialization (init) process in UNIX-based computers to start all the other system services, keep them running, and shut them down.\nUse light-weight init-style system for container as entrypoint, such as runit, tini, BusyBox init, Supervisord, and DAEMON tools.\n\u0026ndash;init: tini program by default evaluate using which init program. The purpose and use of health checks Health checks: check whether the application running inside the container is able to perform its function.\nhealth check command:\nHEALTHCHECK instruction in Dockerfile: should be reliable, lightweight, and not interfere with the operation of the main application because it will be executed frequently (every 30 seconds by default) 0: success, 1: unhealthy, 2: reserved three failed checks from healthy to unhealthy || exit 1\nTime-out : a time-out for health check command to run and exit Start period : grace period docker run \u0026ndash;health-cmd override the health check defined in the image if exists. Building hardened application images Hardening an image means reducing the attack surface inside any Docker containers based on it.\nStrategy:\nminimize the software included with the container enforce that your images are built from a specific image have a sensible default user eliminate a common path for root user escalation from programs with SUID or SGID attributes set Content-addressable image identifiers Content-addressable image identifier (CAIID) refers to a specific layer containing specific content, to enforce a build from a specific and unchanging starting point.\nAppend an symbol @ followed by the digest in place of the standard tag position\nUseful when incorporating known updates to a base into your images and identifying the exact build of the software running on your computer.\nPrevent from changing without your knowledge.\nUser permissions Docker cannot prevent from user run with root permission.\nUSER instruction in Dockerfile to set user and group, similar to docker container run/create .\nThe key is to determine the earliest appropriate time to drop privileges.\ntoo early: active user may not have permission to complete the instructions in Dockerfile Also need to consider the permissions and capabilities needed at runtime, such as system port range (1-1024) Which user should be dropped into?\nimage user do not know about Docker daemon configuration about namespace remap.\ngosu SUID and SGID permissions SUID: file will always execute as its owner, such as /usr/bin/passwd.\nHave the risk of compromise the root account inside a container.\nThe files with SUID and SGID are rarely required for application use cases.\nUnset the SUID and SGID permission for all files in current image:\nRUN for i in $(find / -type f ( -perm /u=s -o -perm /g=s )); do chmod ug-s $i; done\nChapter 9: Public and private software distribution Choosing a distribution method How to choose the appropriate method for your situation.\nA distribution spectrum\nSelection criteria Cost Visibility: secret projects or public works Transportation: transportation speed and bandwidth overhead Longevity Availability \u0026hellip; Publishing with hosted registries Hosted registry: a Docker registry service that is owned and operated by a third-party vendor.\ne.g., Docker Hub, Quay.io, Google Container Registry by default, Docker publishes to Docker Hub Publishing with public repositories: \u0026ldquo;Hello World!\u0026rdquo; via Docker Hub docker login Maintains a map of your credentials for registries that you authenticate.\ndocker image push insert Docker Hub username\u0026gt;/hello-dockerfile Push your repo to the host registry.\ndocker search username Searching repo owned by specific user.\nPrivate hosted repositories Before you can use docker image pull or docker container run to install an image from a private repository, you need to authenticate with the registry where the repository is hosted\nIntroducing private registries Using Docker\u0026rsquo;s registry software\nUsing the registry image Start a local registry in a container:\ndocker run -d -p 5000:5000 -v \u0026ldquo;$(pwd)\u0026quot;/data:/tmp/registry-dev \u0026ndash;restart=always \u0026ndash;name local-registry registry:2 docker image tag dockerinaction/ch9_registry_bound localhost:5000/dockerinaction/ch9_registry_bound docker image push localhost:5000/dockerinaction/ch9_registry_bound Where can we find the image localhost:5000/dockerinaction/ch9_registry_bound?\nRegistry stores the image on /var/lib/registry on its union filesystem, which is volume on the host filesystem by default. So we can find it in the volume of local-registry container. Use docker volume ls to list all the volumes. Use docker volume inspect xxx to display detailed information on the volume.\nNote that we can use -v xxx:/var/lib/registry to mount the /var/lib/registry on a specific location.\nFor \u0026ldquo;$(pwd)\u0026quot;/data:/tmp/registry-dev , mount the volume into the container. The first part \u0026ldquo;$(pwd)\u0026quot;/data is the location of the volume on host machine, the second part is the location on the container union filesystem. Note that in this example, we did not mount /var/lib/registry on this location, so we cannot find the image push to the registry on \u0026ldquo;$(pwd)\u0026quot;/data .\nWhen you’ve started the registry, you can use it like any other registry with docker pull, run, tag, push commands.\nConduct tight version control: pull images from external sources such as Docker Hub and copy them into their own registry. To ensure that an important image does not change or disappear unexpectedly when the author updates or removes the source image.\nConsuming images from your registry docker image rm dockerinaction/ch9_registry_bound localhost:5000/dockerinaction/ch9_registry_bound\ndocker image pull localhost:5000/dockerinaction/ch9_registry_bound This will prevent remote Docker clients from using your registry.\nManual image publishing and distribution Work with images as files.\ndocker image save + docker container export\ndocker image load + docker image import\nImage source-distribution workflows Using github.\nMuch flexible.\nChapter 10: Image pipelines Image build pipeline: preparing image material, building an image, testing, publishing images to registries.\nGoals of an image build pipeline\nApplication artifacts: runtime scripts and configuration files produced by software authors.\nCI tools.\nPatterns for building images How many images an application includes?\nAll-in-One Build plus Runtime Build plus Multiple Runtimes\nAll-in-one images Build the application into an image.\nDownsides:\ncontain more tools than necessary, easy for attackers\nthe size will be large (708MB)\nENTRYPOINT [\u0026ldquo;java\u0026rdquo;,\u0026quot;-jar\u0026rdquo;,\u0026quot;/app.jar\u0026rdquo;]\nSeparate build and runtime images The build-specific tools such as Maven and intermediate artifacts are no longer included in the runtime image.\nMuch smaller size (from 708MB to 401MB) Smaller attack surface. Variations of runtime image via multi-stage builds Multi-stage builds can be used to keep the specialized image synchronized with the application image and avoid duplication of image definitions.\nName a build stage:\neasily to mention the stage by other stages. build processes can build a stage by specifying that name as a build target. docker image build \u0026ndash;target : select the stage to build the image.\nIf do not specify a build stage, docker will build image from the last stage defined in the Dockerfile.\nAdd a trivial build stage at the end of the Dockerfile.\nEnsure app-image is the default image built with this Dockerfile # FROM app-image as default Record metadata at image build time Use LABEL instruction to capture metadata, at least including:\napplication name application version build date and time version-control commit identifier Commonly used labels http://label-schema.org/rc1/: label schema, e.g., LABEL org.label-schema.version=\u0026quot;${BUILD_ID}\u0026rdquo;\nOrchestrating the build with make Make: used to build programs, understands dependencies between the steps of a build process.\nSteps: gathering metadata, building application, building, testing, tagging the image.\nUse linting tool named hadolint to check Dockerfile.\nTesting images in a build pipeline Container Structure Test tool (CST) https://github.com/GoogleContainerTools/container-structure-test verifies the construction of a Docker image.\nverify desired file permissions and ownership, commands execute with expected output, and the image contains particular metadata such as a label or command the tool operates on arbitrary images without requiring any tooling or libraries to be included inside the image. Patterns for tagging images Important image-tagging features:\nTags are human-readable Multiple tags may point to a single image ID Tags are mutable and may be moved between images. Background Image tag mutation is commonly used to identify the latest image in a series.\nHowever, it is difficult to identify what does the latest lag mean?\nContinuous delivery with unique tags Using unique BUILD_ID tag.\nInconvenient for users.\nConfiguration image per deployment stage A generic, environment-agnostic application image. A set of environment-specific configuration image. Semantic versioning A version number of the form Major.Minor.Patch. Author could increment the following:\nMajor version when making incompatible API changes Minor version when adding functionality in a backward-compatible manner Patch version when making backward-compatible bug fixes make tag BUILD_ID=$BUILD_ID TAG=1.0.0\nHigher-level abstractions and orchestration Chapter 11: Service with Docker and Compose Service: any processes, functionality, or data that must be discoverable and available over a network is called a service.\nA service \u0026ldquo;Hello World!\u0026rdquo; Docker services are available only when Docker is running in swarm mode.\ndocker swarm init\ndocker service create \u0026ndash;publish 8080:80 \u0026ndash;name hello-world dockerinaction/ch11_service_hw:v1\nTask is a swarm concept that represents a unit of work. Each task has one associated container.\nAutomated resurrection and replication docker service ls to list the running services.\ndocker service ps hello-world to list the containers associated with a specific service.\nThe desired state is what the user wants the system to be doing, or what it is supposed to be doing.\nThe current state describes what the system is actually doing.\nOrchestrators remember how a system should be operating and manipulate it without being asked to do so by a user.\nyou need to understand how to describe systems and their operation. docker service inspect hello-world to output the current desired state definition for the service:\nName of the service Service ID Versioning and timestamps A template for the container workloads A replication mode: replicated mode and global mode. replicated mode (default) docker service scale hello-world=3 (use docker container ps and docker service ps hello-world to show the effects.) If you scale the service back down (docker service scale hello-world=2), you’ll also notice that higher-numbered containers are removed first. global mode Run one replica on each node in the swarm cluster. Rollout parameters Similar rollback parameters A description of the service endpoint Automated rollout\nIllustration of a Docker swarm\u0026rsquo;s action when deploying an update:\nService converged: the current state of the service is the same as the desired state described by the command.\nService health and rollback docker service update \u0026ndash;rollback hello-world 回滚\n\u0026ndash;update-failure-action to tell Swarm that failed deployment should roll back.\nupdate-max-failure-ratio to tell Swarm to tolerate start failures as long as 0.6 of the fleet is good. After that, the whole deployment will be marked as failed and a rollback will be initiated.\nAdd health check:\nAt last, remove the service: docker service rm hello-world\nDeclarative service environments with Compose V3 Imperative tools: such as docker service create Declarative tools: describe the new state of a system, rather than the steps required to change from the current state to the new state. When the service is complex, the number of imperative commands required to achieve the goals is too large. Then we can adopt a higher-level declarative abstraction (docker stack). Docker stack describes collections of services, volumes, networks, and other configuration abstractions.\nThese environments are described using Docker Compose V3 file format.\nCompose files use YAML language, such as docker-compose.yml.\nA YAML primer Comment support: ( #)\nThree types of data: maps (key: value, the value can be double-quote style or plain style), lists (start by -), scalar values\nTwo styles: flow collections, block style.\nUse indentation to indicate content scope. (only use spaces)\nCollections of services with Compose V3 docker stack deploy subcommands: create and update stacks.\nDocker compose cannot handle delete well: e.g., The Compose file you provided to the stack deploy command did not have any refer to the mariadb service, so Docker did not make any changes to that service.\nusing docker service remove executing docker stack deploy with the \u0026ndash;prune flag Stateful services and preserving data Define volumes in compose file:\nvolumes: volume_name: property (empty definition uses volume defaults)\nThe top-level property defines the volumes that can be used by services within the file.\nDocker can attach the new service to the original volume.\nLoad balancing, service discovery, and networks with Compose Port publishing for a service is different from publishing a port on a container: containers directly map the port on the host interface to an interface for a specific container, services might be made up of many replica containers.\nFor docker services, docker creating virtual IP (VIP) addresses and balancing requests for a specific service between all of the associated replicas.\nFirst network ingress: handles all port forwarding from the host interface to services. Created when you initialize Docker in swarm mode. Second network: shared between all of the services in your stack. Services default attach to a network named default. The address listed here is the container address, or the address that the internal load balancer would forward requests onto. Not the virtual IP addr you would see when inspecting. Define network in compose file:\ntop-level networks property that includes network definitions networks property of services\n"},{"id":2,"href":"/docs/stage1/git/","title":"Git","section":"Docs","content":"git reset\ngit reverse\ngit rebase\ngit rebase main\n当前在bugFix这个branch，把当前的branch copy到main branch\ngit rebase a b\n将b复制到a下\ngit rebase bugFix\ngit rebase bugFix main\ngit pull \u0026ndash;rebase\ngit push origin main (git push )\ngit push origin \u0026lt;source本地\u0026gt;:\u0026lt;destination远\u0026gt;\n如果是空的，例如 git push origin :foo ，那就是删除foo on remote\ngit fetch 和 git pull的区别？git pull = git fetch + merge\ngit fetch origin \u0026lt;source远\u0026gt;:\u0026lt;destination本地\u0026gt;\n如果是空的，例如git fetch origin :bar, 那就是新建bar 分支\n"},{"id":3,"href":"/docs/stage2/k8s-in-action/","title":"K8s in Action","section":"Docs","content":"第一章：Kubernetes 介绍\nKubernetes 通过对实际硬件做抽象，然后将自身暴露成一个平台，用于部署和运行应用程序。它允许开发者自己配置和部署应用程序，而不需要系统管理员的帮助，让开发者聚焦于保持底层基础设施运转正常的同时，不需要关注实际运行在平台上的应用程序。\nK8s系统由一个主节点和若干个工作节点组成。开发者把一个应用列表提交到主节点，k8s会把它们部署到集群的工作节点。组件被具体部署在哪个节点对于开发者和系统管理员来说都不用关心。\n第二章：开始使用K8S和Docker\nkubectl cluster-info 展示集群信息\nkubectl get 列出各种kubernetes对象的基本信息, e.g., kubectl get nodes kubectl describe node xxx 查看更详细的信息\n为kubectl创建别名 alias k=kubectl , tab命令补全\npod: 一组紧密相关的容器，运行在同一个工作节点上，同一个linux命名空间内\n不能用kubectl get 列出单个容器，因为它们不是独立的k8s对象，但是可以列出pod，kubectl get pods\n调度scheduling：将pod分配给一个节点\nkubectl expose re kubia \u0026ndash;type=LoadBalancer \u0026ndash;name kubia-http 创建外部的负载均衡，可以通过负载均衡的公共ip访问pod\nkubia-http服务：解决不断变化的pod IP地址的问题\nReplicationController：负责pod并让它们保持运行\n第三章：pod: 运行于Kubernetes中的容器 介绍pod\n一个pod不会跨越多个工作节点\n想象一个由多个进程组成的应用程序，由于不能将多个进程聚集在一个单独的容器中（很难确定每个进程分别记录了什么），我们需要用pod将容器绑定在一起，作为一个单元进行管理\nKubernetes 通过配置Docker 来让一个pod 内的所有容器共享相同的Linux 命名空间、网络、IPC（进程间通信）命名空间，可以通过IPC进行通信。也可以共享PID命名空间。\n同一pod 中的容器运行的多个进程需要注意不能绑定到相同的端口号（共享network命名空间），否则会导致端口冲突。\n容器可以通过localhost与同一pod中的其他容器进行通信。\n每个pod都可以通过其他pod 的IP 地址来实现相互访问，它们之间没有NAT (网络地址转换） 网关，不管是不是在不同的server上。\n这个平面网络是由额外的软件基于真实链路实现的。\n通过pod合理管理容器\n我们应该将应用程序组织到多个pod 中， 而每个pod 只包含紧密相关的组件或进程。\n多层应用分担到多个pod中，提高基础架构的利用率 pod是扩缩容的基本单位，不同组件有不同的扩缩容要求\n以YAML或JSON描述文件创建pod\nYAML包含：\nKubernetes API 版本 YAML描述的资源类型 metadata spec status （运行时的只读数据，创建pod时不需要提供）\n指定容器端口纯粹是展示性的（informational），但是仍然是有意义的，这样每个使用集群的人都可以快速查看每个pod对外暴露的端口。\nkubectl explain pods 来查看pods支持哪些属性，例如kubectl explain pod.spec\nkubectl create -f xxx.yaml 从YAML文件或JSON创建pod（及其他k8s资源）\nkubectl get po xxx -o yaml 查看该pod的完整描述文件\nkubectl logs xxx 获取pod日志\nkubectl logs pod_name -c container_name pod被删除后，日志也会被删除（需要设置集中的日志系统）\n通过向pod发送请求来测试pod：\n将本地网络端口转发到pod中的端口：kubect1 port-forward kubia-manual 8888:8080\n通过端口转发连接到pod：另开一个终端，curl localhost:8888\n使用标签组织pod\n标签是可以附加到任意k8s资源的键值对。\n一个资源可以拥有多个标签，在创建资源时可以将标签附加到资源上， 之后也可以再添加其他标签， 或者修改现有标签的值。\nkubectl get pods \u0026ndash;show-labels 列出所有标签\nkubectl get po -L xxx,xxx 列出指定的标签\nkubectl label po xxx creation_method=manual 添加标签\nkubectl label po xxx creation_method=manual \u0026ndash;overwrite 更改标签\n通过标签选择器列出pod子集\nkubectl get po -l xxx 标签选择器，多个条件的话用，隔开\n使用标签选择器来约束pod调度\n使用节点标签和节点标签选择器来描述pod对于节点的需求， 使Kubemetes选择一个符合这些需求的节点。\n运维团队向集群添加新节点时，通过标签对节点进行分类，e.g., gpu=true, 唯一标签key为kubernetes.io/hostname，值为该节点的实际主机名\n将pod调度到特定节点：在spec部分添加一个nodeSelector字段\n注解pod\n注解也是键值对，但是不能像标签一样用于对对象进行分组。\n用作为pod或其他对象添加说明，使得使用者可以快速了解信息\n查找对象的注解：获取完整YAML或者JSON文件（k get po xxx -o yaml 或 k describe pod xxx ）\nkubectl annotate pod kubia-manual mycompany.com/someannotation=\u0026ldquo;foo bar\u0026rdquo; 添加注解\n使用命名空间对资源进行分组\n想将对象分割成完全独立且不重叠的组，允许我们多次使用相同的资源名称（跨不同的命名空间）\n如果有多个用户或用户组正在使用同一个Kubernetes 集群，并且它们都各自管理自己独特的资源集合，那么它们就应该分别使用各自的命名空间。不用担心删除更改其他用户的资源，无需担心名称冲突\n命名空间为资源名称提供了一个作用域\n发现、创建、管理命名空间\nk get ns 列出集群中所有的命名空间\nk get po \u0026ndash;namespace(or: -n) xxx 列出xxx命名空间下的pod（默认是列出default下的）\n从YAML文件创建命名空间\nk create namespace xxx 创建命名空间\n命名空间的名字不允许包含点号\n在特定命名空间中创建资源\nYAML文件的metadata字段添加 namespace:xxxx k create -f xxx.yaml -n name_space\nkubectl config 管理默认的命名空间\nkubectl config set context $ (kubectl config current context) \u0026ndash; namespace xxx\n命名空间也行不提供网络隔离（看具体配置）等等隔离\n停止和移除pod\n30秒\n按名称删除pod\nkubectl delete po xxx1 xxx2 xxx3 使用标签选择器删除pod\nk delete po -l xxx=xxx 删除整个命名空间来删除pod\nk delete ns xxx 删除命名空间中的所有pod，但保留命名空间\nk delete po \u0026ndash;all 删除当前命名空间中的所有pod\n删除命名空间中的（几乎）所有资源\nk delete all \u0026ndash;all 第四章：副本机制和其他控制器：部署托管的pod 保持pod健康：存活探针 (liveness probe)\n有三种探针机制：\nHTTP GET探针 TCP套接字探针 Exec探针\n应该给探针设置initialDelaySeconds\n查看之前容器为什么终止，应该看前一个pod的日志，而不是当前pod的：k logs mypod \u0026ndash;previous\n通过k describe po xxx来了解po状态，关注其中的exit code和Events\nExit Code: 128+x, 其中x是终止进程的信号编号。e.g., 137=128+9，9是SIGKILL的信号编号\n如何创建有效的存活探针：\n应该给探针设置initialDelaySeconds，留出应用程序的启动时间 存活探针应该检查什么，应用程序内部 保持探针轻量 无需在探针中实现重试循环\n存活探针运行在pod工作节点上的kubelet，部署运行在主服务器上。如果工作节点本身崩溃，存活探针无法执行任何操作，这时候需要ReplicationController。\nReplicationController\nReplicationController是一种k8s资源，可以确保pod始终保持运行状态\nReplicationController的协调流程\nReplicationController的三个部分：\nlabel selector 标签选择器，用于确定RC作用域中有哪些pod 更改后对现有的pod没有影响，会使现有的pod脱离RC的范围，控制器会停止关注它们 replica count 副本个数，指定运行的pod数量 pod template pod模板，用于创建新的pod副本 更改后只影响RC新创建的pod 创建RC\npod模板中的标签要与RC的selector一致，或者省略selector标签，它会自动根据pod模板中的标签来配置。\n修改pod模板\n不影响旧的pod\nk edit rc kubia 修改pod模板\n水平缩放pod\n陈述式\n更改rc.yaml文件中的spec.replicas\n删除RC\nk delete rc 删除rc，由rc管理的pod也会被删除\nk delete rc \u0026ndash;cascade=false/orphan 删除rc，保留由rc创建的pod\n使用ReplicaSet而不是ReplicationController\n二者区别：ReplicaSet的标签选择器更强\n支持标签组，e.g., RC无法将pod与env=production和env-devil同时匹配，ReplicaSet可以 支持仅基于标签名的存在来匹配pod，类似于env=* 定义ReplicaSet\nk create -f kubia-replicaset.yaml 报错 no matches for kind \u0026ldquo;ReplicaSet\u0026rdquo; in version \u0026ldquo;apps/v1beta2\u0026rdquo;。\n解决方案：查看版本kubectl api-versions，改成app/v1\nk get rs： replicaset的缩写是rs\nk describe rs\nReplicaSet强大的标签选择器\n使用DaemonSet在每个节点上运行一个pod\n希望在集群中的每个节点上运行一个pod（例如日志收集器、资源监控器、kube-proxy进程等系统服务），需要创建DaemonSet对象\nDaemonSet的调度不受节点不可调度属性的影响\n通过pod模板中的nodeSelector属性指定部署到哪些特定的节点\nk get ds DaemonSet缩写是ds\nk label node node_name disk=ssd 给节点打标签\n更改node的标签后，由ds管理的pod也会被删除\n运行执行单个任务的pod\nJob资源：运行一个pod，这个pod在任务完成后，变成完成状态。例如，临时任务（需要以正确的方式结束）\n在发生节点故障时，该节点上由Job 管理的pod将按照ReplicaSet 的pod 的方式，重新安排到其他节点。\n如果进程本身异常退出（进程返回错误退出代码时）， 可以将Job 配置为重新启动容器。\n定义Job资源\n其中的restartPolicy属性指定容器中运行的进程结束时，k8s会做什么。默认是always，但是job资源不能使用默认策略。因此要将restartPolicy设定为OnFailure或者Never\n在Job中运行多个pod实例\n也可也通过缩放job来更改parallelism属性：k scale job job_name \u0026ndash;replicas 3\n限制Job pod完成任务的时间\n在pod template中设置activeDeadlineSeconds属性来限制pod时间。如果超过这个时间，系统就会终止pod，并将job标记为失败。\n安排Job定期运行或在将来运行一次 创建CronJob\ncron时间表格式，从左到右分别是 分钟 小时 每月中的第几天 月 星期几。\n对于对时间要求较高的任务，可以设置startingDeadlineSeconds来设置截止时间。到了截止时间不执行任务会直接failed。\n服务：让客户端发现pod并与之通信 介绍服务\nk8s服务：为一组相同功能的pod提供单一不变的接入点的资源。\n服务存在时，它的IP地址和端口号不会改变（pod的IP地址可能会改变），客户端通过IP和端口号建立连接，连接会被路由到提供该服务的任意一个pod上。因此，客户端不需要知道每个pod的地址。\n服务通过标签选择器来指定pod\n创建服务 k expose 通过yaml文件\n在80端口接受请求，然后路由到标签选择器app=kubia的pod的8080端口上\nservice的缩写是svc\n在运行的容器中远程执行命令\nk exec pod_name \u0026ndash; curl -s http://10.111.249.153\n其中，双横杠“\u0026ndash;”表示k命令项的结束，双横杠之后的内容是pod内部需要执行的命令\n会话亲和性\n希望特定客户端产生的所有请求每次都指向同一个pod\nspec.sessionAffinity = ClientIP 会话亲和性不能基于cookie\n端口命名\n同一个服务可以暴露多个端口（需要给每个端口指定名字），但是标签选择器是针对整个服务的，不能对每个端口做单独的配置\n可以命名端口，好处是即使更改端口号也无需更改服务spec\n服务发现\n客户端pod如何知道服务的IP和端口？\n通过环境变量发现服务\n如果创建的服务早于客户端pod的创建，可以客户端pod可以通过环境变量获取服务的IP和端口号\nKUBIA_SERVICE_HOST 服务集群的IP 和 KUBIA_SERVICE_PORT 服务所在的端口，所有字母大写，横杠被转化成下划线\n通过DNS发现服务\npod kube-dns 运行DNS服务，集群中的其他pod使用其作为dns（k8s通过修改每个容器的/etc/resolv.conf实现）\npod是否使用内部DNS服务器是根据pod中spec的dnsPolicy属性来决定的\n通过全限定域名（Fully qualified domain name,FQDN）连接服务\nFQDN链接：服务名称.命名空间.svc.cluster.local\n其中svc.cluster.local是集群本地服务名称中使用的可配置集群域后缀\n如果两个pod在同一个命名空间下，可以省略命名空间和svc.cluster.local后缀\n无法ping通服务IP的原因\n在pod内ping服务ip无法成功，因为这是一个虚拟IP，只有在和服务端口结合时才有意义\n连接集群外部的服务\n通过k8s service的特性暴露外部服务，不要让服务将连接重定向到集群中的pod，而是重定向到外部IP和端口\n可以利用服务负载均衡的特点\n介绍Endpoints资源\nEndpoints资源：暴露一个服务的IP地址和端口的列表\nk get endpoints kubia 缩写ep\n尽管定义了Selector标签选择器，但是在重定向传入连接时不会直接使用它。标签选择器用于构建IP和端口列表，然后储存在Endpoint资源中。在客户端连接到服务时，服务代理选择这些IP和端口对中的一个，并将传入连接重定向到该位置监听的服务器\n手动配置服务的endpoint\n创建没有标签选择器的服务\n为没有标签选择器的服务创建Endpoint资源\nEndpoints对象需要与服务具有相同的名称\n其中，11.11.11.11:80和22.22.22.22:80是外部IP:端口的例子\n为外部服务创建别名\n通过FQDN访问外部服务\n服务创建后，可以通过external-service.default.svc.cluster.local域名（甚至external-service）连接到外部服务，不需要外部服务实际的FQDN\nExternalName服务仅在DNS级别实施，因此连接到服务的客户端将直接连接到外部服务，绕过了服务代理\n将服务暴露给外部客户端\n需要向外部公开某些服务，例如前端web服务器，以便外部客户端可以访问它们\n三种方式：\n将服务的类型设置成NodePort 将服务的类型设置成LoadBalance 创建一个Ingress资源 使用NodePort类型的服务\n可以通过内部集群IP访问NodePort服务，还可以通过任何节点IP和预留节点端口访问NodePort服务\n指定集群节点的节点端口不是必需的。如果忽略，k8s会随机选择一个端口\n可以通过以下地址访问该服务：\n10.100.138.138:80 \u0026lt;1st node\u0026rsquo;s IP\u0026gt;:30123 \u0026lt;2nd node\u0026rsquo;s IP\u0026gt;:30123\n到达任何一个节点30123端口的传入连接将被重定向到一个随机选择的pod，该pod是否位于接收到连接的节点上是不确定的\n创建LoadBalance类型的服务\nLoadBalancer类型的服务是一个具有额外的基础设施提供的负载均衡器NodePort服务\n了解外部连接的特性 防止不必要的网络跳数\n当外部客户端通过节点端口连接到服务时，随机选择的pod不一定在接受连接的同一节点上运行，需要额外的网络跳转才能到达pod\n可以将服务配置为仅将外部通信重定向到接收连接的节点上运行的pod来阻止此额外跳数（local外部流量策略）\n如果没有本地pod存在，连接将挂起，并不会转发到随机的全局pod（缺点一，需要负载均衡器将连接转发给至少具有一个pod的节点）\n缺点二：可能导致负载分配不均衡\n客户端IP是不记录的\n当通过节点端口接收到客户端的连接时， 由于对数据包执行了源网络地址转换(SNAT), 因此数据包的源IP将发生更改，无法得知实际的客户端IP\n如果使用local外部流量策略，那么IP不会更改，因为在接受连接的节点和托管目标pod的节点之间没有额外的跳跃。\n通过Ingress暴露服务\nIngress只需要一个公网IP就能为许多服务提供访问，在网络栈（HTTP）应用层操作\nNo ingress pod on the server\nIngress工作原理：不会直接将请求转发给该服务，而是用它来选择一个pod\n通过相同的ingress暴露多个服务 将不同的服务映射到相同主机的不同路径\npath和rules都是数组。可以根据URL中的不同路径，通过同一个IP地址（Ingress控制器的IP地址）访问两个不同的服务\n将不同的服务映射到不同的主机上\nDNS需要将foo.example.com和bar.example.com都指向ingress控制器的IP地址\n配置Ingress处理TLS传输\n客户端和控制器之间的通信是加密的，而控制器和后端pod之间的通信则不是\nIngress负责处理与TLS相关的所有内容\npod就绪后发出信号 介绍就绪探针 就绪探针类型：Exec探针、HTTP GET探针、TCP socket探针\n向pod中添加就绪探针\n使用headless服务来发现独立的pod 将service的spec中的clusterIP设置为None，就会使服务成为headless服务。\nk8s不会为headless服务分配集群IP，客户端可以通过这个IP连接到支持它的pod\n"},{"id":4,"href":"/docs/stage1/linux1/","title":"Linux1","section":"Docs","content":"第零章 计算机基础 操作系统是连接硬件和用户的，让用户不用对着机器文档编程，更方便 操作系统用来有效率地控制计算机的硬件资源，并且提供方便程序员编程的接口\n第一章 Linux是什么 网路基础： http://www.study-area.org/network/network.htm\n在Linux系统中， 每个设备都被当成一个文件来对待\n第二章 主机规划与磁盘分区 第三章 安装一个Linux系统 简单翻过去了\n第四章 首次登陆与线上求助 man指令学到了很多小技巧，比如/search 一些数字的含义 如果忘记指令了怎么办？ man后面的一些后缀 nano Tmux 使用教程 - 阮一峰的网络日志 (ruanyifeng.com) vimtutor\nVim 配置入门 - 阮一峰的网络日志 (ruanyifeng.com)\n第五章 Linux文件权限与目录配置 各种权限查看和更改 ls -l chgrp, chown, chmod 各种权限是什么含义，尤其是目录文件的 注意目录的x权限 绝对目录、相对目录\n第六章 Linux文件与目录管理 .和..和~ PATH rmdir 删除空目录 rm-r 删除不空的目录 mv除了移动文件，也可以用作文件的更名 管线|：前一个指令输出的讯息，通过管线交给后续的指令继续使用 eg：cat -n /etc/man_db.conf | head -n 20 | tail -n 10 分号；：在一行中输入多个指令 touch 创建新的空文件，修改 /atime（access读取时间）和mtime（modify修改时间），不能修改ctime（status time） 查阅文件内容 cat, less, more, tail, head 默认权限 umask 文件 666 默认没有x（不可执行） 目录 777 默认有x（可以进入目录） 特殊权限 SUID、SGID、SBIT 4 SUID：使用者执行这一程序时，执行过程中会暂时拥有程序拥有者的权限，例如：passwd修改自己的密码 2 SGID：使用者在这个目录下新建的文件的群组都会和该目录的群组名称相同 小组作业，小组内部成员可以同一个目录底下工作，但是小组成员还是拥有自己的家目录和私有群组，那么可以新建小组群组并将小组成员添加到这个群组，新建小组任务文件夹，然后将该文件夹权限设置为2770（13章任务二例题） 1 SBIT：该目录下使用者创建的文件只有自己与root能够删除 chattr和lsattr设置观察隐藏属性 which查指令 whereis查文件很快，后面要接文件的完整名字 locate查文件也很快，并且后面不需要接完整的名字，但是因为查的是数据库里的数据，所以有时候需要updatedb来更新数据库 updatedb执行比较慢 find 很万能 find [PATH] [option] e.g., find / -name \u0026lsquo;passwd\u0026rsquo;\n第七章 Linux磁盘和文件系统 ext文件系统: superblock, inode, block journal: 多一个记录区记录系统主要活动，可以加快系统复原时间 xfs文件系统: 格式化快，能处理大文件 hard link和symbolic link hard link 实体链接多了一个文件名对该inode号码的链接 symbolic link 符号链接，类似win的快捷方式 分区gdisk，格式化mkfs，挂载mount 内存置换空间swap\n第八章 压缩打包与备份 压缩: gzip, bzip2, xz (压缩比越来越高，压缩速度越来越慢) 打包: tar 压缩+打包的文件叫做tarball\n备份：xfsdump, xfsrestore\n第九章 Vim :sp 可以分窗口，ctrl+w+上/下 可以控制不同的窗口 其他的可以现查 暂存档 .swp\n第十章 BASH 之前的指令在.bash_history中\necho$variable 定义变量 myname=VBird 环境变量env, export, 所有变量set export variable, 将自定义变量变成环境变量，分享自己的变量设定给后来的其他程序 取消变量 unset read -pt variable 读取键盘输入作为变量 declear 声明变量的类型 shell里面的很多设置和配置文件介绍 source 配置文件名，不需要注销再登录，直接将修改后的设定写入配置文件 stty [-a] seeting tty的各个按键参数（例如 ctrl c等） bash中的特殊符号与通配符 $?表示前一个指令执行完毕后的回传值，为0表示执行成功\n双星号 **/*.war: 所有文件夹下的 .war 文件 *.war: 当前文件夹下的 .war 文件 数据流重导向：指令执行后应该出现在屏幕上的数据给传到其他地方去\n, \u0026raquo;, 2\u0026gt;, 2\u0026raquo; example 1: command \u0026gt; doc1 2\u0026gt; doc2 stdout存到doc1 stderr存到doc2 example 2: command 2\u0026gt; /dev/null 黑洞装置/dev/null，将错误信息吃掉，既不显示在屏幕上又不储存 example 3: command \u0026gt; doc 2\u0026gt;\u0026amp;1 将stdout和stderr写入同一个文件 同理也有 1\u0026gt;\u0026amp;2 \u0026lt;, \u0026laquo; \u0026lt; 用文件内容取代键盘输入 \u0026laquo; 后接结束的输入字符 tee：同时输出给文件和屏幕 e.g.: python run.py 2\u0026gt;\u0026amp;1 | tee train.log 多条命令一次输入来执行 cmd1; cmd2 指令之间没有相关性。 cmd1 \u0026amp;\u0026amp; 或 || cmd2 前一个指令是否成功执行与后一个指令是否要执行相关 假设判断式：cmd1 \u0026amp;\u0026amp; cmd2 || cmd3 管线pipe 与连续下达命令的区别？ | ：只能处理前一个指令传来的正确信息, i.e., stdout, 不能处理错误信息\n能够接受std input的命令才是管线命令 less, more, cat等可以 ls, cp, mv 等这些不行 硬要处理错误信息的话，就用数据流重导向2\u0026gt;\u0026amp;1 撷(xie 2)取命令 行 为单位 cut 处理特定分割的数据，例如echo ${PATH}中有\u0026quot;：\u0026quot; 处理排列整齐的数据，例如export 处理多空格相连的数据比较费劲 grep 取出有特定信息‘text’的那一行 排序命令 sort 重复的信息只显示一个 uniq，配合排序过的文件来处理，先sort再uniq 输出数据各种计数 wc：行、字数、字符数 同时将数据流输出给文件和屏幕：tee tr 删除或者替换文字 col 将tab键转换成对等的空格键 和expand什么区别？ join 将两个文件中有 相同数据 的那一行加在一起 join之前，先排序 paste 将文件两行贴在一起，用tab来分隔 file如果写成-，代表资料来自standard input expand将tab转成空格键 和col什么区别？ 分区命令 split 将大文件分成小文件 分区之后合并，用数据流重导向\u0026raquo;就可以了 参数代换 xargs：产生某个指令的参数 xargs可以读入stdin的数据，并且以空白或者断行字符作为分辨，将stdin的数据分隔成arguments xargs [-0epn] command -n 后面接次数，每次command执行需要几个参数的意思 主要用法：很多指令不是管线命令，用xargs来引导这些指令使用std input id command的例子 另一个用法：数据量很大，使用xargs每次丢几个给command处理（11章第一个例题） “-” 前一个指令的stdout作为这次的stdin，那么stdout和stdin可以用“-”来替代 一个区分：type 指令是何种类型，file 是文件是什么类型\n第十一章 正规表示法与文件格式化处理 正规表示法，regular expression, 正则表达式 搜索、删除、取代特定的字符串，以行为单位 有些工具支持正规表示法，比如grep，有些不支持，比如cp, ls，它们只能使用bash自己本身的通配符 与通配符有什么区别？ 通配符(wildcard)是bash操作环境里的东西，是bash的一个功能 正则表示法是字符串处理的一种表示方式 基础正规表示法 搜索特定字符串 grep \u0026rsquo;text\u0026rsquo; file 利用中括号[]搜索集合字符 e.g., \u0026rsquo;t[ae]st\u0026rsquo;, []里面代表一个字符，这个字符是a或者e e.g., \u0026lsquo;[^a-z]oo\u0026rsquo;, oo前面不能是小写字母 e.g., \u0026lsquo;[^[:lower:]]oo\u0026rsquo;, oo前面不能是小写字母 行首^，行尾$ e.g., \u0026lsquo;^the\u0026rsquo;, 以the开头 e.g., \u0026lsquo;^[a-z]\u0026rsquo; 或者 \u0026lsquo;^[[:lower:]]\u0026rsquo;, 以小写字母开头 \u0026ldquo;^\u0026ldquo;符号在字符集合符号[]内外的含义不同，在[]内表示反向选择，在[]外表示行首 e.g., \u0026lsquo;.$\u0026rsquo; 以.结尾的行，注意使用跳脱字符\n空白行 \u0026lsquo;^$\u0026rsquo; \u0026ldquo;.\u0026ldquo;一定有一个任意字符，\u0026rdquo;\u0026ldquo;重复前一个字符0到无数次 \u0026lsquo;o\u0026lsquo;指的是空字符或者一个及以上o, \u0026lsquo;oo*\u0026rsquo; 指的是有一个以上o \u0026lsquo;.*\u0026rsquo; 指零个或多个任意字符 {} 限定字符范围 e.g., e.g., \u0026lsquo;go{2,5}g\u0026rsquo;, g后面接2到5个o，再接一个g 注意使用跳脱字符\ne.g., \u0026lsquo;go{2,}g\u0026rsquo;, 接2个以上o sed工具 是个管线命令，用来分析standard input 后面接的动作，要用单引号\u0026rsquo; \u0026lsquo;括住 如果接超过两个以上的动作，那么每个动作前要加上 -e 功能 新增、插入、删除 （整行）取代、显示 部分数据的搜寻取代 sed \u0026rsquo;s/要被取代的字符串/新的字符串/g\u0026rsquo; -i 直接修改文件内容，要小心 延伸正规表示法 egrep \u0026ldquo;+\u0026rdquo; 一个或一个以上前一个字符：o+表示一个以上的o \u0026ldquo;?\u0026ldquo;零个或一个前一个字符：o? 表示空或者一个o \u0026ldquo;|\u0026rdquo; 或，\u0026lsquo;gd|good\u0026rsquo;, gd或good \u0026ldquo;()\u0026rdquo; 找出群组字符串 搜寻glad或good：g(la|oo)d \u0026ldquo;()+\u0026rdquo; 重复群组 格式化打印 printf printf \u0026lsquo;打印格式\u0026rsquo; 实际内容 不是管线命令 printf \u0026lsquo;%s\\t %s\\t %s\\t \\n\u0026rsquo; $(cat printf.txt) %8.2f, 五位整数，两位小数，一位小数点，总共八位 数据处理工具awk 是个管线命令，可以处理std input或者文件 $1$, $2$ \u0026hellip; 代表第x个字段 字段间以空格或者tab键隔开 $0$ 代表一整行 每次处理一行，字段是最小处理单位 BEGIN 关键词 预先设定awk的变量 awk里面的\u0026rsquo;\u0026lsquo;变成“” 文件对比 diff 是管线命令 以行为单位对比 除了对比文件，也可以对比目录 cmp 也是管线命令 只能对比文件 以字节为单位对比 patch 补丁档，将旧的文档升级到新的文档 比较新旧版本的差异，将差异档制作成为补丁档，用补丁档更新旧文件 文件打印 pr 文件时间，文件档名，页码 第十二章 Shell Scripts 如何执行一个shell scripts文件（首先要有rx权限） /绝对路径/shell.sh 相对路径，./shell.sh 将shell.sh放在PATH目录里，然后可以直接 shell.sh bash shell.sh （只要有r权限就可以） source shell.sh 【在父程序bash执行】 写一个shell script程序 第一行 #!/bin/bash\n注释说明 # script的功能，版本信息，较特殊的需要使用绝对路径的方式来下达的指令，需要的环境变量宣告与设定 宣告环境变量 主要程序 执行结果告知（回传值） 数值计算 var=$((运算内容)) 判断式 test指令 判断文件是否存在，什么类型权限，文件比较，字符串数据等 反状态，test ! -x file 判断符号 [ ] 每个组件之间都需要空格来分隔 变量需要用双引号括号起来 常量需要用单或双引号括号起来 e.g., [ [] \u0026ldquo;$HOME\u0026rdquo;[]==[]\u0026quot;$MAIL\u0026rdquo;[] ] 经常用在条件判断式中 if\u0026hellip;then\u0026hellip;fi 默认变量 可以通过 script.sh variable 来直接给变量，也可以通过read交互式 $0: 文件名 $1, $2, $3 \u0026hellip;. 第一、二、三\u0026hellip;个参数 $#: 参数数目 $@: 全部的参数内容，i.e., \u0026ldquo;$1\u0026rdquo; \u0026ldquo;$2\u0026rdquo; \u0026ldquo;$3\u0026rdquo; \u0026ldquo;$4\u0026rdquo;\u0026hellip;\u0026hellip; 变量偏移shift number，拿掉最前面的几个参数 条件判断式 单层、简单的 if [条件判断式]; then \u0026hellip; fi [] || [] 或者 \u0026amp;\u0026amp; 多层的 if [条件判断式]; then \u0026hellip; else \u0026hellip; fi if [条件判断式一]; then \u0026hellip; elif [条件判断式二]; then \u0026hellip; else \u0026hellip; fi case\nfunction功能\n要放在程序最前面 也有默认变量 $0, $1, $2\u0026hellip;.. $0指的是function函数名称 $1, $2 \u0026hellip;都和script的不一样，是函数的 循环 loop 不定循环\n固定循环\nvar的值分别是con1，con2，con3cu $(seq \u0026hellip;) e.g.: $(seq 1 100) 也可以用 {1..100}\n可以用 i++ shell script 追踪与debug bash [-nvx] scripts.sh 书上的command用的是sh，但是其实是bash，我没有设置sh是bash的alias，如果用sh的话，for数值循环会报错 第十三章 账号管理与ACL权限设定 账号与群组 /etc/passwd 文件 /etc/shadow 文件 /etc/group 文件 群组、有效群组（command groups 出来的第一个群组，作用在新建文件）、初始群组（passwd中的第四栏） newgrp来切换有效群组，是以另一个shell来提供这个功能的，所以结束后要exit\nexit后有效群组又变回去了 /etc/gshadow 文件，用来设置群组管理员 账号管理 useradd建立账号 -s /sbin/nologin 使得用户无法登入系统取得shell /etc/skel 用户家目录的参考基准目录，家目录中的默认数据是由这个目录复制过去的 /etc/login.defs UID/GID/密码参数等 passwd 修改（设置）密码 chage 详细的密码参数 usermod 微调useradd的参数 root通过usermod -a user1 -G group1 将user1新加到group1 userdel 删除用户数据 finger, chfn, chsh groupadd, groupmod, groupdel 要删除群组，要确认没有账号使用该群组作为初始群组，否则无法删除 群组管理员 gpasswd 小组作业，小组内部成员可以同一个目录底下工作，但是小组成员还是拥有自己的家目录和私有群组，那么可以新建小组群组并将小组成员添加到这个群组，新建小组任务文件夹，然后将该文件夹权限设置为2770（13章任务二例题） 外部身份验证系统 authconfig-tui: CentOS的，Ubuntu没有这个指令 主机的细部权限规划: ACL的使用 Access Control List，为单一的用户或群组设定权限 设定ACL权限 setfacl，查找ACL权限 getfacl setfacl -R 与 setfacl -m d\u0026hellip;.的区别：前者是递归设定之前已经存在的文件的ACL权限，后者是未来文件的ACL权限 要设定一个用户/群组没有任何ACL权限，权限的地方不能直接留白，要加上一个“-”减号 使用者身份切换 su \u0026ldquo;-\u0026rdquo;: 使用login shell的方式切换身份，完整切换 \u0026quot; \u0026ldquo;：使用non-login shell的方式 sudo 能否执行sudo要看/etc/sudoers 使用visudo来修改/etc/sudoers，不能直接vi /etc/sudoers 后接用户自己的密码来确认执行后续的指令 可以设置 sudo su - 用户的特殊shell与PAM模块 PAM这块书上是以CentOS为例的，我在ubuntu上没有找到文件在哪里啊 找到了，/usr/lib/x86_64-linux-gnu/security/ 用户信息传递 查询使用者：w, who, lastlog 使用者对谈：write 拒绝接收信息 mesg n，但无法拒绝来自root的信息 对所有系统上在线的用户广播：wall 邮件：mail 账号检查工具 Ubuntu 的passwd指令没有–stdin 可以用chpasswd 一个大量新建设置账号的脚本模板 第十四章 磁盘配额(Quota)与进阶文件系统管理 什么是Quota? 让磁盘容量公平的分配 我的文件系统是ext4，并且/home不是独立的文件系统（mounted on 根目录），所以先跳过了14.1这一节 磁盘阵列RAID: 将多个较小的磁盘整合成为一个较大的磁盘装置 RAID选择的不同level RAID-0：等量模式 stripe。只要有任何一颗磁盘损毁，在RAID上面的所有数据都会遗失无法读取 RAID-1：映像模式 mirror。同一份数据完整保存在两颗磁盘上。 RAID 1+0：最推荐\nRAID-5：有同位检查码，可以支持一颗磁盘损毁的情况\n同为检查数据（奇偶校验位）是什么？Parity占的存储空间不会是A0+B0的总和吗？ 我理解的奇偶校验只能知道传输有没有错误，不能用来恢复啊。好像也可以？ 为什么是round robin写入的？ 另有RAID-6，允许同时两颗磁盘损毁的情况 预备磁盘 spare disk 不支持热插拔的话关机才能动手插拔硬盘 一些优点 数据安全和可靠性：硬件损毁的话能不能安全恢复 读写：RAID 0可以改善系统I/O 扩大容量 因为硬件磁盘阵列很贵，所有利用软件来仿真磁盘阵列的功能 → 软件磁盘阵列 第七章的练习没怎么做 我遇到的问题 gdisk /dev/sda\n逻辑滚动条管理员 实现一个可以弹性调整容量的文件系统 第十五章 例行性工作排程（crontab） 什么是？ 将Linux的例行性工作安排执行的流程 分类 at：仅执行一次，突发性的 crontab：例行性的，每隔一定周期就要办的事情 一些例行性工作 仅执行一次的工作排程 确保atd启动 /etc/at.deny at指令 背景执行功能 atq查询，atrm删除指令 batch指令 在CPU的工作负载小于0.8时，再进行工作任务 循环执行的例行性工作排程 默认启动 crontab指令 一些注意事项 资源分配不均 周和日月不可同时共存 可唤醒停机期间的工作任务 anacron 主动帮忙执行时间到了但是却没有执行的排程 时间戳 第十六章 进程管理与SELinux初探 什么是进程？ 进程是一个正在运作中的程序 进程呼叫 fork and exec 服务deamon：常驻在内存中的进程，文件名以d结尾 工作管理 job control 工作管理是当我们登入系统取得bash shell之后，在单一终端机接口下同时进行多个工作的行为管理 管理的工作都是当前bash的子进程 前景foreground，背景background vim不可能在背景中running job control的管理 直接将指令丢到背景中执行：command+ \u0026amp;，最好使用数据流重导向 将目前的工作丢到背景中，并暂停：ctrl + z 观察目前的背景工作状态：jobs 将背景工作拿到前景来处理：fg %+数字 让工作在背景下的状态从暂停变成运行中：bg 移除工作：kill 脱机管理 要注意工作管理的背景仍然和终端机有关，脱机注销之后工作不会继续进行，会中断 工作需要一大段时间，要如何处理 使用at tmux nohup 进程管理 进程的观察 ps：某个时间点的进程运作情况 僵尸进程 defunct ps aux 所有进程 ps -l 自己的bash相关进程 top：动态观察进程的变化 pstree：更直观地看进程相关性 进程的管理 信息传递 signal 常用编号 1：重新启动 9：强制中断 15：正常中止 kill -signal PID/%jobnumber killall -signal 指令名称 不需要配合ps来找到进程的ID，而是直接用名称 进程的执行顺序 (priority) CPU排程：每支进程被CPU运行的演算规则 优先执行序 priority，PRI：越低越优先 核心动态调整的，用户无法直接调整PRI值 优先级高的程序每秒被运作的次数更多 用户可以条件的是NI值，i.e., nice值 条件范围-20~19，一般使用者无法调到负值 指令：nice，renice 修改nice值可以在父进程子进程之间传递 系统资源的观察 free 内存使用情况 uname 查询系统与核心相关信息 uptime 系统启动时间与工作负载 netstat 追踪网络或插槽文件 dmesg 分析核心产生的讯息 vmstat 侦测系统资源变化，看看哪个部分的资源被使用的最频繁 特殊文件与进程 有SUID和SGID权限的指令执行状态 程序与进程的区别：SUID程序在运行过程中产生的进程 /proc 里面的文件 查询已开启文件或者已执行进程开启的文件 fuser：某个文件（或文件系统）目前正被哪些进程所利用 lsof：某个进程开启或者使用的文件与装置 pidof：某支正在被执行的程序的PID 另外也可以用 ps aux 配合 grep + 正则表达式 SELinux Security Enhanced Linux，安全强化的linux 传统的文件权限与账号关系，i.e.，自主式访问控制DAC比较危险，所有使用依据政策规则制定特定进程读取特定文件的委托式访问控制MAC 运作模式 主体：进程；目标：文件资源\n安全性本文可以想成SELinux内必备的rwx SELinux的重要属性：Type（文件资源）/domain（进程） 三种模式： 强制、宽容、关闭 要切换模式的话得重新启动 第十七章 系统服务daemons deamons和服务是什么？ 达成某个服务的程序叫做daemon systemd启动服务机制 一些概念： 服务单位unit，服务类型type：每种服务单位按照功能来划分，可以分成不同的服务类型 操作环境target是服务类型的一种，是一群unit的集合 主要服务类型 systemd启动过程中，无法与管理员透过standard input传入信息 systemctl管理服务 单一服务的 systemctl [command] [unit] 如果用kill来关闭一个正常的服务，那么systemctl就无法继续监控这个服务了 deamon的各种状态：active，enabled等 注意service部分用start/stop/restart，target项目用isolate systemctl list-dependencies 网络服务与对应端口 systemctl针对service类型的配置文件 配置文件相关目录 配置文件的设定项目 配置文件整体分为三个部分：Unit, Service, Install 每个部分下面有很多参数 简化多个执行的启动设定\n将执行文件中的@范例名称带入到源文件中的%I systemctl针对timer的配置文件 和crond类似，定期执行任务 在ubuntu上叫timers.target 第十八章 认识与分析登录档 登录档是什么：记录系统在什么时候由哪个程序做了什么样的行为，发生了何种的事件 一般只有root有权限读取 常见的登录档 /var/log/syslog rsyslog.service stand alone deamon 配置文件 /etc/rsyslog.conf 语法在这里 /etc/rsyslog.d/50-default.conf 服务名称、讯息等级、被记录在哪里 服务名称与讯息等级之间的连接符号【.】表示\u0026gt;=后面严重程度的都记录下来 不需要登录等级 .none\n文件名前的“-”：先将讯息存储在速度较快的内存中，等数据量够大了再一次性填入磁盘内 编辑登录档后restart rsyslog.service 可以添加chattr属性来保护登录档，防止手误更改了文件 一些区分\n登录档服务器 登录档的轮替（logrotate） logrotate是挂在cron底下进行的 主要功能 将旧的登录档改名字移动成旧档，然后新建新的登录档，旧的登录档一段时间后删除\n配置文件 /etc/logrotate.conf /etc/logrotate.d 基本语法 档名，得是绝对路径 参数，monthly等等 执行脚本，需要sharedscripts, prerotate, postrotate, endscript 加了chattr的a属性后不能，文件不能直接更名成功，需要在配置文件里先把a参数去掉，然后再更名，然后再加上这个属性 systemd-journald.service systemd-journald.service用来管理与查询这次开机后的登录信息，而rsyslogd用来记录以前及现在的数据到磁盘中，方便未来查询 journalctl指令：查询systemd-journald.service的数据 logger指令：将我的数据存储到登录文件中 分析登录档 logwatch\n第十九章 开机流程、模块管理与Loader Linux开机流程分析\n第一支程序systemd PID号码是1号 准备软件执行的环境，包括主机名、网络设定等服务的启动 操作环境target 通过systemctl list-dependencies graphical.target 来观察systemd的大致开机流程\n脚本放在/etc/rc.d/rc.local文件里，可以开机执行 用到的主要配置文件 加载额外的核心参数设定/etc/modules-load.d/.conf、/etc/modprobe.d/.conf 常见的环境配置文件 /etc/sysconfig/* 核心与核心模块 核心（kernel），目前都具有可读取模块化驱动程序的功能，也就是modules模块化，可以把它想象成插件 核心相依性 modules.dep 显示所有模块 lsmod 模块信息 modinfo 加载模块 modprobe，会自动检查相依性 Boot Loader：Grub 略过这一节了 开机过程的问题解决 忘记root密码 开机以root执行bash 文件系统错误 第二十章 基础系统设定与备份策略 系统基本设定 网络设定 nmcli指令来手动设定 DHCP自动分配 hostnamectl 主机名 日期和时间设定 timedatectl 显示时区时间 语系设定 防火墙简易设定 服务器硬件数据收集 dmidecode解析硬件配备 观察硬件状态信息的指令：gdisk, dmesg, vmstat, lspci, lsusb, iostat 了解磁盘的健康状态 smartd 虚拟机不支持 备份 要备份哪些数据 /etc /home /root /var/spool/mail/, /var/spool/cron/, /var/spool/at/ /var/lib/ 备份的种类 完整数据备份 累积备份 差异备份 关键数据备份 备份策略 每周备份的script cp、tar、crontab 每日备份的script cp、tar、crontab 远程备援的script rsync、ssh 第二十一章 软件安装：原始码与Tarball 开放源码的软件安装 开放源码、编译程序、可执行文件 什么是可执行文件：二进制文件 什么是开放源码：程序代码，纯文档 什么是编译程序：将程序代码转译成机器看得懂的语言 程序代码（纯文档）通过编译程序，利用已存在的函数库，编译成可执行文件\n函式库 什么是函式库：被呼叫来执行的一段功能函数 make和configure make，makefile 通过侦测程序主动建立makefile，侦测程序的文件名一般为configure或config\nTarball软件 将源代码打包压缩，解压后里面一般有 源代码文件 侦测程序文件（configure或者config） 简易说明README、或者INSTALL 使用C语言进行编译的简单范例 gcc hello.c 直接编译原始码 gcc -c 仅编译成目标文件object file，并不制作链接等功能 产生hello.o，不产生二进制执行档 原始码文件并非只有一个文件，无法直接进行编译 用make进行宏编译 简化编译时需要下达的指令 仅针对修改了的文件编译，其他的object file不会被更动 基本语法\n#批注 变量\n$@ 代表当前的目标 target 环境变量取用规则 make指令列后面加上的环境变量优先 makefile里面的第二 shell原本的环境变量第三 Tarball的管理与建议\n大部分安装流程需要的指令 .configure make clean make make install 建议软件安装在/usr/local下，原始码tarball放在/usr/local/src下 利用diff，patch更新软件 patch的功能是更新原始码文件，还是要将软件进行编译后，才能最终得到正确的软件 如果版本跨度较大没有对应的patch文件，需要依序更新 函式库管理 动态与静态函式库 静态函式库 .a：编译的时候直接整合到执行程序当中，编译后的可执行文件可以独立执行 函式库升级后，整个执行档必须重新编译 动态函数库 .so，没有整合到执行文件当中，程序里面只有一个指针pointer的位置，编译出来的程序不能独立执行 函式库文件必须要存在，所在的目录也不能改变 函式库更新后，无需重新编译，函式库的升级方便 将常用的动态函式库加载到内存中，增进读取速度：ldconfig 判断可执行binary文件里面含有哪些动态函式库：ldd 检查软件的正确性 检查文件的指纹码 可以为重要的文件建立指纹数据库（例如/etc/shadow），然后写脚本定期检查指纹表是不是变化了 第二十二章 软件安装RPM，SRPM与YUM\nRPM有软件属性相依的问题，所以出现了YUM机制\n现在主要利用rpm来做查询\n"},{"id":5,"href":"/docs/stage2/linux2/","title":"Linux2","section":"Docs","content":"第二章：基础网络概念 什么是网络 制定标准 计算机网络的组成组件 节点node：有网络地址（IP）的设备 服务器主机server：提供数据以响应给用户的主机 工作站workstation：可以在计算机网络输入的设备 客户端client：主动发起联机去要求数据的工作站是客户端 网络卡network interface card：提供网络联机功能；一般node都有\u0026gt;=1 个网络卡 网络接口：主要功能是提供网络地址（IP） 网络形态或拓扑typology：节点在网络上的链接方式，例如星型等 网关route或通讯闸gateway 计算机网络的区域范围 局域网 LAN 广域网 WAN 计算机网络协议 open system interconnection OSI 七层协议 越接近硬件的阶层为底层（layer 1），越接近应用程序的越高层（layer 7） 就像一个套一个的包裹，包裹表面是表头header，包裹里面是实际数据 TCP/IP 协议 将七层协议简化为四层\nTCP/IP 链结层相关协议 广域网的设备 局域网使用的设备：以太网络（Ethernet） 以太网络网卡之间的数据传输：CSMA/CD 标准 （Carrier Sense Multiple Access with Collision Detection） 监听 多点传输 碰撞侦测 讯框frame，MAC MAC就是讯框，因为上面有目标与来源的网卡卡号，所以简称网卡卡号是MAC MAC (Media Access Control) 上面有以太网络卡卡号（hardware address，硬件地址），是十六进制的6字节数据 使用ifconfig来查询网卡卡号 资料里大小限制 46-1500bytes 要碰撞侦测，数据量至少64bytes，扣除地址什么的是46bytes，如果不足的话系统会自动填上填充码 MTU, maximum transmission unit，最大传输单位，默认1500，最大9000 改大一些可以减少封包数据的拆解，进而提升网络利用率，但是不是所有的网络媒体都支持大的MTU，可能会导致封包无效，所以不建议改大 集线器hub、交换机switch 区别：交换机克服了封包碰撞的问题，不是网络共享媒体（就像hub那样的十字路口） TCP/IP 网络层相关封包和数据 IP封包 TTL存活时间、Protocol封包协议、来源和目标地址 IP地址 32bits，分成四小段，每段8bits，对应一个0-255的十进制数字 网段等级\n主要用的是class A，B，C 以class c的网段等级为例，前三小段是网域号码Net_ID，后一段是主机号码Host_ID 同一个网域：同一个物理网段内，有相同的Net_ID，独特的Host_ID Host_ID全为0（对应十进制0）表示整个网段的地址network ip，全为1（对应十进制255）表示广播地址 broadcast ip，这两个不可以做为网段内的主机IP设定，i.e., 1-254 同一个物理网段内， 同一个网域：CSMA/CD在网域内广播联机，或者网卡对网卡传递数据（MAC讯框） 不同网域：无法通过广播的方式联机，要通过路由器router来将两个网域连结在一起 IP的种类 共有IP public IP，私有IP private IP 预留的私有IP网段，不能直接连互联网\nClass A里的lo网域是内部循环网络，网段127.0.0.0/8，默认主机localhost ip是127.0.0.1 IP的取得方式 手动设定 通过拨接取得 自动取得网络参数DHCP Netmask，子网，CIDR Netmask，或subnet mask子网掩码 Net_ID全部为1，Host_ID全部为0\n子网切分：分割成更小的网域 让一部分Host_ID被拿来作为Net_ID 无层级IP: CIDR 无等级网域间路由，打破原来IP代表等级的方式 Network/Netmask的写法\n路由 封包传递功能 路由表 IP与MAC：链结层的网络地址解析和反向网络地址解析 网络地址解析ARP：取得IP和MAC的对应 ARP table 因特网讯息控制ICMP协定 是一个错误侦测与回报的机制，用来确保网络的联机状态和联机的正确性 ping, traceroute 注意设置防火墙时的ICMP设置 TCP/IP 传输层 可靠联机的TCP协议 表头：来源端和目标端端口 port 特权端口：root才能启动\nclient向server端要数据，客户端随机取一个\u0026gt;1024且空闲的port socket pair IP: port 三向交握 可靠，但是慢 SYN，ACK 非连接导向的UCP协议 不需要联机确认 实时，不可靠，例如实时传输影像 网络防火墙 设定分析规则来分析封包的表头 连上Internet Domain Name System, DNS：主机名hostname与IP对应的协议 上网需要如下的网络设定 IP Netmask Network（可以计算得到） Broadcast（可以计算得到） Gateway DNS 第三章 局域网络架构简介 局部网络联机\n第四章 连上Internet 主要配置文件\n前两个文件没有在ubuntu里找到 五大检查步骤（page 141） 查看IP参数对不对，重点的IP与Netmask：ifconfig 检查路由设定是否正确 route -n 检查能否与路由器联机成功 ping gateway_IP 查看DNS是否顺利运作了 dig www.google.com 检查主机名有没有对应的ip ping -c 3 see-prc-qleng-vm01 常见问题说明 内部网域遇到的联机延迟问题：联机时期慢，联机成功后速度恢复正常 网络联机时，两部主机间会使用DNS系统来做主机名与IP对应的查询（/etc/resolv.conf） 但是内部网域的IP无法使用/etc/resolv.conf的设定来查询这部主机的名称 但是可能会发生持续查询主机名的动作，持续30-60秒 解决方法：在/etc/hosts内加入每部主机名称与IP的对应 能ping通雅虎的ip，但是无法以网址连上Internet 修改/etc/resolv.conf 预设路由 有多个预设路由可能会混乱，所以不要在ifcfg-eth0中指定GATEWAY等变量 第五章 Linux常用网络指令 网络参数设定使用的指令 设定与启动、关闭IP参数 ifconfig 使用eth0:0是设置虚拟网络接口，也就是在一张网络卡上设置多个ip ifup, ifdown 通过搜寻配置文件ifcfg-ethx来启动与关闭的，我的ifcfg-ethx在哪里啊。。。 路由修改 route gateway = 0.0.0.0 表示是直接由本主机传送，也就是通过局域网的MAC直接传；如果显示ip，就表示该路由需要经过路由器的帮忙才可以传送出去 0.0.0.0/0.0.0.0是预设路由\n如果在一部主机上面设置两个相同网域的ip，那么所有封包都会从eth0传出去，多此一举 综合指令 ip 无线网络 iwlist, iwconfig 手动使用DHCP自动取得IP参数：dhclient 网络侦错与观察指令 两部主机两点沟通：ping 传送ICMP封包去要求对方主机回应 两部主机间各节点分析：traceroute 如果联机到某个外部网站的速度比平时慢，为了检查是自己的网络环境问题还是外部的Internet问题，就可以使用traceroute 查看本机的网络联机和后门：netstat 服务名称与port number的对应在/etc/services 侦测主机名与IP对应 host hostname nslookup dig 都是使用/etc/resolv.conf来查询 远程联机指令 telnet 数据在传送的时候使用明码，不安全 ftp, lftp: 传输大文件 文字接口网页浏览 文字浏览器 links 主要用来 查看由HTML语法写成的文件数据 使用vim看的话，会看到一堆HTML语法 也可以用来浏览网页 文字接口下载器 wget 网络数据的取得 不需要浏览器，直接可以下载网页的数据 设置proxy：/etc/wgetrc 封包撷取功能 网络联机出现问题，使用ping又找不到问题点，这时可以分析封包的流向 文字接口封包撷取器 tcpdump 图形接口的 wireshark 启动任意port：nc 可以用来取代telnet 第六章 Linux网络侦错 无法联机原因分析 硬件问题 软件问题 IP参数设定 路由设定 通讯协议不相符 网络负荷 防火墙设定等 问题处理 从硬件开始，从自身的网络卡查起，到网络线、Hub等等 网络卡工作确认 确认网络卡已经驱动成功 lspci/dmesg 确认可以手动建立IP参数 ifconfig + ping 局域网络内各项连接设备检测 思考软件问题 了解问题 确认IP，取得正确的IP参数 确认区网联机 确认对外联机 ping无法连接到外部的主机，很可能是防火墙或路由的问题 ppp0? 确认DNS查询 主机名与IP查询的DNS错误 host www.google.com Linux的NAT服务器或IP分享器出问题 确认Internet节点 traceroute 确认对方服务器正常工作 确认我方服务器 netstat 防火墙或权限 tcpdump\n第七章 网络安全与主机基本防护 网络封包联机进入主机的流程\n防火墙 封包过滤防火墙，主要看表头信息 TCP Wrappers 常见的攻击手法与相关保护 取得账户信息后猜密码 利用系统的程序漏洞主动攻击 利用社交工程作欺骗 利用程序功能的“被动”攻击 蠕虫或木马的rootkit DDOS (Distributed Denial of Service)攻击法 主机能做的保护 软件更新 关闭不必要的网络服务 权限设置 网络自动升级软件 限制联机端口\n这些服务尽量不要关掉 SELinux管理原则 控制的主体是程序，而不是使用者 被攻击后的主机修复工作 第八章 路由观念与路由器设定 路由 路由表 由小网域到大网域 主机上面的网络接口会对应存在一个路由 我的VM里面，为什么route不是从10.67.127.0啊？\n明白了，注意看子网掩码 一个网卡多个IP：IP Alias 重复路由问题 不能单纯地在同一网域设定两个IP来增加主机的网络流量\n路由器架设 路由器功能：【传递网络封包】分析来源端封包的IP表头，在表头内找到要送达的目标IP，然后透过路由器本身的路由表来将封包往下一个目标传送 Linux的核心也有封包传递（IP forward）功能 确认变量 /proc/sys/net/ipv4/ip_forward是1，也就是linux核心启动了封包传递 静态路由 route指令 动态路由 Quagga软件等 NAT服务器 路由器+IP转换 修改封包的IP表头数据，让私有IP的封包可以转成公有IP，连上Internet 一个例子：静态路由\nLinux Router 设置 Router A路由设置：让clientlinux可以连上Internet 让workstation与clientlinux不透过Router A沟通 要注意路由是双向的，要了解出去的路由和回来时的规则 动态路由器架设：quagga软件 动态路由协议：RIPv1，RIPv2，OSPF，BGP\n动态路由经常用于两个router之间沟通彼此的路由规则 路由器两边界面是同一个IP网段 如果两块网卡都是同一网域的IP会发生错误（重复路由问题）\n使用ARP代理功能，让适配卡的MAC代理其他主机的IP 例如让PC2-4的IP对应的网卡卡号都设定在外部eth0上，将PC1给PC2-4的封包骗过来 同样地，内部eth0代理PC1的IP，将PC2给PC1的封包骗过来 第九章 防火墙与NAT服务器 什么是防火墙？ 分析与过滤进出我们管理的网域的封包数据 规划出 切割被信任与不被信任的网段 划分出可以提供Internet的服务与必须受保护的服务 分析出可接受与不可接受的封包状况 主要类别 封包过滤机制 Netfilter：分析封包的表头数据 TCP Wrappers 程序控管：针对程序（名称，vsftpd）来分析谁能联机，谁不能联机 代理服务器 proxy：代理用户的需求，代为前往服务器取得相关的资料 防火墙的一般网络布线示意 单一网域，仅一个路由器\n内部网络包含需要更安全的子网防火墙\n在防火墙后面架设网络服务器主机\n非军事区（DMZ） 防火墙的使用限制 TCP Wrappers /etc/hosts.allow与/etc/hosts.deny 只有部分软件可以通过这个来管理 super daemon所管理的服务 有支援libwrap.so模块的服务 查看是否有libwrap动态函式库：ldd指令 规则的优先顺序 通过启动档的档名来管理的，所以得先观察配置文件知道档名是什么 封包过滤软件：iptables防火墙机制 规则顺序很重要：对比与分析顺序 iptable的表格(table)与链(chain) 至少有filter、nat、mangle三个表格，mangle用得很少 每个表格里又有链\niptable语法 iptables指令 iptables-save指令 定义防火墙的预设政策，iptables -P 封包的基础比对设定 针对端口的TCP、UDP的规则比对 iptables外挂模块：mac与state 这个想要进入的封包是否为刚刚我发出去的相应，\u0026ndash;state ESTABLISHED, RELATED 针对网卡进行放行和防御 ICMP封包规则对比 开放部分ICMP封包格式进入本机进行网络检测的工作 可以将ICMP type 8 拿掉，让远程主机不知道我们是否存在 iptables-save, iptables-restore IPv4的核心管理功能 SYN Cookie:降低无效的SYN等待端口，避免DoS攻击中的SYN Flooding攻击 取消部分ping响应 可以针对不同的网络接口进行不一样的参数设定 单机防火墙的一个实例 NAT服务器的设定 NAT: network address translation, 网络地址转换 IP分享器+路由器 修改IP封包的表头数据，包括目标或来源IP 修改TCP封包表头的port number NAT table prerouting链 修改目标IP，Destination NAT，DNAT postrouting链 修改来源IP，Source NAT，SNAT SNAT: 内部LAN连接到Internet\n将来自private IP的封包表头伪装成public IP，然后将这个封包传送出去 收到来自Internet的封包，核实封包的序号，发现是后端主机之前发送出去的，所以将目标IP修改为后端主机，然后最终传送到对应的后端主机上 DNAT：内部LAN架设可以让Internet存取的服务器\nNAT将来自外部主机封包的目标IP改为192.168.1.210，然后封包传到内部WWW服务器 WWW服务器响应数据给61.xxxxxx，这个回应传给192.168.1.2，经过NAT服务器将来源IP改成public IP后，传给61.xxxxx NAT服务器得有一个public IP接口，和一个内部LAN连接的private IP接口 注意要进行路由的检测 第十章 申请合法的主机名 DNS得通过注册的方式来取得合法授权\n"},{"id":6,"href":"/docs/stage1/make_file/","title":"Make File","section":"Docs","content":"概述 makefile关系到了整个系统的编译规则，哪些文件需要先编译，哪些后编译等等 自动化编译 Makefile的规则\n如果prerequisites后面的文件比target文件新，就执行command 执行：make 一层层地找文件的依赖关系，直到最终编译出第一个目标文件 变量 $(obj) 自动推导 make看到.o文件会自动把.c文件加在依赖关系prerequisites中 clean make clean 才会执行 放在文件的最后\n"},{"id":7,"href":"/docs/stage1/tmux/","title":"Tmux","section":"Docs","content":"将会话（还有内部的进程）与窗口解绑的工具\n几个名词：\nsession 会话，理解成任务 window 窗口，当前呈现在面前的终端界面就是窗口 pane 窗格，把窗口切割成一小块一小块 一个会话可以有多个窗口，一个窗口可以又可以分隔成多个窗格 还允许多人实时共享对话\n会话session操作\n新建会话：tmux new -s 分离会话：tmux detach / ctrl+b d 查看所有会话：tmux ls 接入会话：tmux attach -t tmux attach -t 0 会话编号 杀死会话： tmux kill-session -t 会话编号/ 切换会话：tmux switch -t 会话编号/ 重命名会话：tmux rename-session -t 会话编号/session-name 快捷键 ctrl+b d 分离会话 ctrl+b s 列出所有会话 ctrl+b $ 重命名当前会话 查看session历史输出信息: 进入指定会话后，按ctrl+b，松开后按[，就可以进入历史输出信息查看模式，按q退出 窗格pane操作\n划分窗格(pane) tmux split-window [-h] 移动光标 tmux select-pane -U/D/L/R 快捷键\n窗口操作\n新建窗口 tmux new-window -n 切换窗口 tmux select -window -t \u0026lt;name/number\u0026gt; 重命名窗口 tmux rename-window 快捷键\n"},{"id":8,"href":"/docs/stage2/udemy/","title":"Udemy","section":"Docs","content":"Section 1: 持续集成和Jenkins介绍\n持续集成 在开发过程中尽早地发现bug 持续集成、持续交付、持续部署的区别\n持续集成：个人研发的部分向软件整体的部分交付。频繁进行集成可以更快地发现其中的问题 持续交付：将集成后的代码交付到类生产环境中 持续部署：自动部署到生产环境中 2. Jenkins介绍 Jenkins是持续集成和构建服务器 Java写的，开源的 Section 2: 环境配置和Jenkins安装 java version：1.8.0 （Java 8）\nJenkins version: 2.121.3，这个版本很多plugin用不了了，所以改用2.346.1\nSection 3: Jenkins架构、术语、UI介绍、创建第一个Jenkins Job Master和Slave架构\nmaster改成main了\n关键术语 Job/Project: 由Jenkins监视或控制的任务 Slave/Node: node是所有的机器，包括slave和master slave agent：jenkins在slave上运行一个单独的程序 slave注册到master之后，master开始向slave分配负载 Executor: 独立的构建流，一个node可以有\u0026gt;=1个executor Build: 一个build是一个job/project的结果 Plugin: 拓展核心jenkins服务核心功能的软件 Jenkins UI manage plugin报错怎么办\n创建第一个Jenkins Job 运行第一个Jenkins Job 注意manage Jenkins -\u0026gt; manage plugin →advanced 中的HTTP Proxy Configuration\nenter image description here\nSection 4: 用Jenkins持续集成 安装Jenkins GitHub plugin 第一个基于maven的Jenkins项目 Maven 什么是maven 描述软件是如何构建的 描述项目的依赖 安装的时候注意设置PATH Maven中的pom.xml文件：描述正在构建的软件项目 Maven构建软件生命周期中的不同阶段 validate, compile, test, package, verify, install, deploy 只需要调用要执行的最后一个构建阶段 注意要给maven设置proxy\n要把里面的username和userpasswd删掉 在Jenkins中进行源代码控制轮询 Cron语法\nSCM means source code management\n几个触发器 build periodically：不集成，只是执行任务 Section 5: Jenkins 持续检查 代码质量和代码覆盖率度量报告 check style: java代码静态分析工具 已经下架了，现在改用 warning next generation了 configuration里这样写\n还有一些其他的静态分析工具 PMD FindBugs Jenkins支持的其他构建系统 Ant, Gradle, Shell脚本\nSection 6: Jenkins 持续交付 归档构建artifacts staging环境上安装和配置tomcat 部署到staging环境上\n线性管道 Jenkins构建pipeline 可视化界面\n并行的进行Jenkins构建 -\u0026gt; checkstyle可能花费很长时间 让staging尽快开始\n部署到生产环境上\n必须手动触发 如何在一个机器上同时运行两个tomcat程序：运行在不同的端口 staging: port 8091 production: port 9091\nSection 7: Jenkins Pipeline as Code (Jenkinsfile) 把Web应用程序管道转化成代码 版本控制 执行job不容易漏掉步骤 Jenkinsfile：领域专用语言 代码格式介绍\n创建Pipeline Job Jenkinsfile handbook parallel 并行运行任务 Section 8: Jenkins和Docker集成 先跳过了\nSection 9: 分布式构建\n需要master节点能够SSH免密登录到slave节点 以我的VM作为master节点，NUC作为slave节点 Jenkins上新建节点 给节点加上标签，使得job运行在特定标签的节点（机器）上 在node configure中\n"}]